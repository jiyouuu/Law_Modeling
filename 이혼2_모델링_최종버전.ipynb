{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4115FjGL53J",
        "outputId": "9dc23b79-a5c7-4d98-a485-2042a244f2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.12/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (495 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m495.9/495.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.6.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xxrksfm6LtCR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import joblib, json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcUHoSMJMDDv",
        "outputId": "1e005a5a-38ac-4da1-d5a3-fa28916d23f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/ë²•ë¥ ëª¨ë¸ë§/divorce_topic_labeled_corrected.csv\", encoding=\"utf-8-sig\")"
      ],
      "metadata": {
        "id": "cuij0VDAMEGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"/content/drive/MyDrive/ë²•ë¥ ëª¨ë¸ë§/divorce_topic_labeled_testVersion.csv\", encoding=\"utf-8-sig\")"
      ],
      "metadata": {
        "id": "ZMqGs2D4lGoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intent_map = {\n",
        "    \"ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\": 0,\n",
        "    \"ì ˆì°¨Â·ë°©ë²•\": 1,\n",
        "    \"ì¦ê±°Â·ì…ì¦\": 2,\n",
        "    \"ê¸ˆì•¡Â·ì‚°ì •\": 3,\n",
        "    \"ê¸°ê°„Â·ì‹œíš¨\": 4,\n",
        "    \"ì œì¬Â·êµ¬ì œìˆ˜ë‹¨\": 5,\n",
        "    \"ë²•ì  ê·¼ê±°Â·ì¡°ë¬¸\": 6,\n",
        "    \"ê°œë…Â·ë²”ìœ„Â·ê¸°ì¤€\": 7,\n",
        "    \"ê¸°íƒ€\" :  -1}\n",
        "topic_map = {\n",
        "    \"ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\":0,\n",
        "    \"ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬\":1,\n",
        "    \"ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„\":2,\n",
        "    \"ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\":3,\n",
        "    \"ì¼ë°˜ ìƒë‹´Â·ìƒí™© ë¬¸ì˜ (ë¹„ë²•ë¥ ì  ì§ˆë¬¸)\": 4}"
      ],
      "metadata": {
        "id": "Y9g2C-px235r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8FLgF3flTKW",
        "outputId": "868ddd61-6e2e-4094-ee3b-99e569c990e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['announce_date', 'input', 'output', 'is_divorce', 'input_processed',\n",
              "       'text_combined', 'combined_processed', 'topic_label',\n",
              "       'topic_probability', 'topic_name'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "\n",
        "\n",
        "X_intent = df1[\"input\"]  # ì›ë³¸\n",
        "y_intent = df1[\"intent_name\"]\n",
        "\n",
        "X_topic = df1[\"input_processed\"]  # ì „ì²˜ë¦¬ë³¸\n",
        "y_topic = df1[\"topic_name\"]\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# ==============================\n",
        "# 2ï¸âƒ£ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ í•¨ìˆ˜\n",
        "# ==============================\n",
        "def optimize_model_intent(save_path):\n",
        "    X_intent_train, X_intent_test, y_intent_train, y_intent_test = train_test_split(\n",
        "        X_intent, y_intent, test_size=0.2, random_state=42, stratify=y_intent)\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        (\"tfidf\", TfidfVectorizer()),\n",
        "        (\"clf\", LinearSVC(C =1.2, class_weight=\"balanced\")),\n",
        "    ])\n",
        "\n",
        "    # ğŸ’¡ íƒìƒ‰ ë²”ìœ„ (ë„ˆë¬´ ë„“íˆë©´ ì˜¤ë˜ ê±¸ë¦¼)\n",
        "    param_grid = {\n",
        "      \"tfidf__analyzer\": [\"char\", \"char_wb\"],     # wordëŠ” íš¨ê³¼ ê±°ì˜ ì—†ìŒ (ì˜ë¯¸ ê¸°ë°˜ ëª¨ë¸ ì•„ë‹˜)\n",
        "      \"tfidf__ngram_range\": [(1, 2), (2, 4)],     # 3~6ì€ ì˜¤íˆë ¤ ê³¼ì í•© or ë¶ˆí•„ìš”í•˜ê²Œ í¼\n",
        "      \"tfidf__max_features\": [3000, 6000],        # 10000ì€ ê±°ì˜ íš¨ê³¼ ì—†ìŒ\n",
        "      \"clf__C\": [0.8, 1.0, 1.2, 1.5]              # 2.0ì€ ì°¨ì´ ê±°ì˜ ì—†ìŒ\n",
        "  }\n",
        "\n",
        "    print(\"\\nğŸ§  [law_intent] GridSearchCV íƒìƒ‰ ì¤‘...\")\n",
        "    grid_intent  = GridSearchCV(\n",
        "        pipe,\n",
        "        param_grid,\n",
        "        cv=3,\n",
        "        scoring=\"f1_weighted\",\n",
        "        n_jobs=-1,\n",
        "        verbose=2\n",
        "    )\n",
        "    grid_intent.fit(X_intent_train, y_intent_train)\n",
        "\n",
        "\n",
        "\n",
        "    best_intent = grid_intent.best_estimator_\n",
        "    preds = best_intent.predict(X_intent_test)\n",
        "\n",
        "    print(\"\\nâœ… [law_intent] ìµœì  ì¡°í•© ë°œê²¬!\")\n",
        "    print(grid_intent.best_params_)\n",
        "    acc = accuracy_score(y_intent_test, preds)\n",
        "    print(f\"ğŸ“ˆ [law_intent] ì •í™•ë„: {acc:.4f}\")\n",
        "    print(\"=== ë¶„ë¥˜ ë¦¬í¬íŠ¸ ===\")\n",
        "    print(classification_report(y_intent_test, preds))\n",
        "\n",
        "    joblib.dump(best_intent, \"/content/drive/MyDrive/intent_model_hybrid.joblib\")\n",
        "    print(\"ğŸ’¾ law_intent ëª¨ë¸ ì €ì¥ ì™„ë£Œ âœ…\")\n",
        "\n",
        "    return best_intent\n",
        "\n",
        "\n",
        "def optimize_model_topic(save_path):\n",
        "    X_topic_train, X_topic_test, y_topic_train, y_topic_test = train_test_split(\n",
        "        X_topic, y_topic, test_size=0.2, random_state=42, stratify=y_topic)\n",
        "\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        (\"tfidf\", TfidfVectorizer()),\n",
        "        (\"clf\", LinearSVC(C =1.2, class_weight=\"balanced\")),\n",
        "    ])\n",
        "\n",
        "    # ğŸ’¡ íƒìƒ‰ ë²”ìœ„ (ë„ˆë¬´ ë„“íˆë©´ ì˜¤ë˜ ê±¸ë¦¼)\n",
        "    param_grid = {\n",
        "        \"tfidf__analyzer\": [\"char\", \"char_wb\"],     # wordëŠ” íš¨ê³¼ ê±°ì˜ ì—†ìŒ (ì˜ë¯¸ ê¸°ë°˜ ëª¨ë¸ ì•„ë‹˜)\n",
        "        \"tfidf__ngram_range\": [(1, 2), (2, 4)],     # 3~6ì€ ì˜¤íˆë ¤ ê³¼ì í•© or ë¶ˆí•„ìš”í•˜ê²Œ í¼\n",
        "        \"tfidf__max_features\": [3000, 6000],        # 10000ì€ ê±°ì˜ íš¨ê³¼ ì—†ìŒ\n",
        "        \"clf__C\": [0.8, 1.0, 1.2, 1.5]              # 2.0ì€ ì°¨ì´ ê±°ì˜ ì—†ìŒ\n",
        "    }\n",
        "\n",
        "\n",
        "    print(\"\\nğŸ§  [law_topic] GridSearchCV íƒìƒ‰ ì¤‘...\")\n",
        "    grid_topic  = GridSearchCV(\n",
        "        pipe,\n",
        "        param_grid,\n",
        "        cv=3,\n",
        "        scoring=\"f1_weighted\",\n",
        "        n_jobs=-1,\n",
        "        verbose=2\n",
        "    )\n",
        "    grid_topic.fit(X_topic_train, y_topic_train)\n",
        "\n",
        "\n",
        "\n",
        "    best_topic = grid_topic.best_estimator_\n",
        "    preds = best_topic.predict(X_topic_test)\n",
        "\n",
        "    print(\"\\nâœ… [law_topic] ìµœì  ì¡°í•© ë°œê²¬!\")\n",
        "    print(grid_topic.best_params_)\n",
        "    acc = accuracy_score(y_topic_test, preds)\n",
        "    print(f\"ğŸ“ˆ [law_topic] ì •í™•ë„: {acc:.4f}\")\n",
        "    print(\"=== ë¶„ë¥˜ ë¦¬í¬íŠ¸ ===\")\n",
        "    print(classification_report(y_topic_test, preds))\n",
        "\n",
        "    joblib.dump(best_topic, \"/content/drive/MyDrive/topic_best.joblib\")\n",
        "    print(\"ğŸ’¾ law_topic ëª¨ë¸ ì €ì¥ ì™„ë£Œ âœ…\")\n",
        "\n",
        "    return best_topic\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 3ï¸âƒ£ intent + topic ëª¨ë¸ ìµœì í™”\n",
        "# ==============================\n",
        "intent_model = optimize_model_intent(\"/content/drive/MyDrive/intent_model_hybrid.joblib\")\n",
        "topic_model  = optimize_model_topic(\"/content/drive/MyDrive/topic_best.joblib\")\n",
        "\n",
        "# ==============================\n",
        "# 4ï¸âƒ£ ì˜ˆì‹œ ì˜ˆì¸¡\n",
        "# ==============================\n",
        "examples = [\n",
        "     \"ìœ„ìë£Œ ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?\",\n",
        "    \"ì´í˜¼ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
        "    \"ë°°ìš°ìê°€ ì™¸ë„í–ˆì–´ìš”.\",\n",
        "    \"ì¦ê±°ë¥¼ ê¼­ ì œì¶œí•´ì•¼ í•˜ë‚˜ìš”?\",\n",
        "    \"ì´í˜¼ í›„ì—ë„ ì¬ì‚°ë¶„í• ì´ ê°€ëŠ¥í•œê°€ìš”?\",\n",
        "    \"ì–‘ìœ¡ë¹„ë¥¼ ì•ˆ ì£¼ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
        "    \"ì´í˜¼ í›„ì—ë„ ì–‘ìœ¡ë¹„ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\",\n",
        "    \"ì •ì„œì  ë°°ì‹ ë„ ë¶€ì •í–‰ìœ„ë¡œ ì¸ì •ë˜ë‚˜ìš”?\",\n",
        "    \"ìƒë‹´ì€ í™”ìƒìœ¼ë¡œë„ ê°€ëŠ¥í• ê¹Œìš”?\",\n",
        "]\n",
        "\n",
        "print(\"\\n=== ğŸ” ìµœì  ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ===\")\n",
        "for q in examples:\n",
        "    intent_pred = intent_model.predict([q])[0]\n",
        "    topic_pred = topic_model.predict([preprocess_text(q)])[0]\n",
        "\n",
        "    print(f\"ğŸ—¨ï¸ {q}\")\n",
        "    print(f\"â¡ï¸ ì˜ë„(law_intent): {intent_pred}\")\n",
        "    print(f\"â¡ï¸ ì£¼ì œ(law_topic): {topic_pred}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyKKdXJ1eflE",
        "outputId": "578675da-01c8-46f7-f3b4-d3472f681599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ§  [law_intent] GridSearchCV íƒìƒ‰ ì¤‘...\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "\n",
            "âœ… [law_intent] ìµœì  ì¡°í•© ë°œê²¬!\n",
            "{'clf__C': 1.2, 'tfidf__analyzer': 'char', 'tfidf__max_features': 3000, 'tfidf__ngram_range': (1, 2)}\n",
            "ğŸ“ˆ [law_intent] ì •í™•ë„: 0.8118\n",
            "=== ë¶„ë¥˜ ë¦¬í¬íŠ¸ ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨       0.70      0.82      0.76        34\n",
            "    ê°œë…Â·ë²”ìœ„Â·ê¸°ì¤€       0.69      0.58      0.63        19\n",
            "       ê¸ˆì•¡Â·ì‚°ì •       0.80      0.87      0.83        23\n",
            "       ê¸°ê°„Â·ì‹œíš¨       0.73      0.73      0.73        22\n",
            "          ê¸°íƒ€       0.00      0.00      0.00         1\n",
            "    ë²•ì  ê·¼ê±°Â·ì¡°ë¬¸       0.83      0.75      0.79        40\n",
            "       ì ˆì°¨Â·ë°©ë²•       0.92      0.77      0.84        57\n",
            "     ì œì¬Â·êµ¬ì œìˆ˜ë‹¨       0.76      0.91      0.83        32\n",
            "       ì¦ê±°Â·ì…ì¦       0.90      0.93      0.92        59\n",
            "\n",
            "    accuracy                           0.81       287\n",
            "   macro avg       0.70      0.71      0.70       287\n",
            "weighted avg       0.82      0.81      0.81       287\n",
            "\n",
            "ğŸ’¾ law_intent ëª¨ë¸ ì €ì¥ ì™„ë£Œ âœ…\n",
            "\n",
            "ğŸ§  [law_topic] GridSearchCV íƒìƒ‰ ì¤‘...\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "\n",
            "âœ… [law_topic] ìµœì  ì¡°í•© ë°œê²¬!\n",
            "{'clf__C': 0.8, 'tfidf__analyzer': 'char', 'tfidf__max_features': 3000, 'tfidf__ngram_range': (1, 2)}\n",
            "ğŸ“ˆ [law_topic] ì •í™•ë„: 0.8641\n",
            "=== ë¶„ë¥˜ ë¦¬í¬íŠ¸ ===\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "     ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„       0.88      0.74      0.80        61\n",
            "         ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°       0.82      0.86      0.84        72\n",
            "        ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬       0.85      0.93      0.89        73\n",
            "ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)       0.88      0.88      0.88        52\n",
            "ì¼ë°˜ ìƒë‹´Â·ìƒí™© ë¬¸ì˜ (ë¹„ë²•ë¥ ì  ì§ˆë¬¸)       0.96      0.93      0.95        29\n",
            "\n",
            "             accuracy                           0.86       287\n",
            "            macro avg       0.88      0.87      0.87       287\n",
            "         weighted avg       0.87      0.86      0.86       287\n",
            "\n",
            "ğŸ’¾ law_topic ëª¨ë¸ ì €ì¥ ì™„ë£Œ âœ…\n",
            "\n",
            "=== ğŸ” ìµœì  ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ===\n",
            "ğŸ—¨ï¸ ìœ„ìë£Œ ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì¦ê±°Â·ì…ì¦\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì ˆì°¨Â·ë°©ë²•\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ë°°ìš°ìê°€ ì™¸ë„í–ˆì–´ìš”.\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„\n",
            "\n",
            "ğŸ—¨ï¸ ì¦ê±°ë¥¼ ê¼­ ì œì¶œí•´ì•¼ í•˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì¦ê±°Â·ì…ì¦\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼ í›„ì—ë„ ì¬ì‚°ë¶„í• ì´ ê°€ëŠ¥í•œê°€ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ ì–‘ìœ¡ë¹„ë¥¼ ì•ˆ ì£¼ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì ˆì°¨Â·ë°©ë²•\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼ í›„ì—ë„ ì–‘ìœ¡ë¹„ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ ì •ì„œì  ë°°ì‹ ë„ ë¶€ì •í–‰ìœ„ë¡œ ì¸ì •ë˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„\n",
            "\n",
            "ğŸ—¨ï¸ ìƒë‹´ì€ í™”ìƒìœ¼ë¡œë„ ê°€ëŠ¥í• ê¹Œìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì¼ë°˜ ìƒë‹´Â·ìƒí™© ë¬¸ì˜ (ë¹„ë²•ë¥ ì  ì§ˆë¬¸)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intent_model = joblib.load(\"/content/drive/MyDrive/intent_model_hybrid.joblib\")\n",
        "topic_model = joblib.load(\"/content/drive/MyDrive/topic_best.joblib\")\n",
        "\n",
        "df2[\"pred_intent\"] = intent_model.predict(df2[\"input\"])\n",
        "df2[\"pred_topic\"] = topic_model.predict(df2[\"input\"].apply(preprocess_text))\n",
        "print(\"\\n=== ğŸ” ìµœì  ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ===\")\n",
        "\n",
        "# ìƒìœ„ ëª‡ ê°œ ë¯¸ë¦¬ë³´ê¸°\n",
        "for i, row in df2.head(10).iterrows():  # 10ê°œë§Œ í™•ì¸\n",
        "    print(f\"ğŸ—¨ï¸ {row['input']}\")\n",
        "    print(f\"â¡ï¸ ì˜ë„(law_intent): {row['pred_intent']}\")\n",
        "    print(f\"â¡ï¸ ì£¼ì œ(law_topic): {row['pred_topic']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZmcsDz6jNQT",
        "outputId": "f45ee5c6-56ef-4249-daea-90554a76e1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ğŸ” ìµœì  ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ===\n",
            "ğŸ—¨ï¸ ì´í˜¼ ì‹œ ì¬ì‚°ë¶„í•  ì²­êµ¬ê°€ ì–´ëŠ ì •ë„ ì¸ì •ë  ìˆ˜ ìˆë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ í˜¼ì¸ê´€ê³„ì—ì„œ ë¶€ì •í–‰ìœ„ë¥¼ ì €ì§€ë¥¸ ë°°ìš°ìê°€ ì´í˜¼ í›„ ì•½ì •í•œ ê¸ˆì•¡ì„ ì§€ê¸‰í•˜ì§€ ì•ŠëŠ” ê²½ìš°, ë²•ì  ì¡°ì¹˜ëŠ” ì–´ë– í•œê°€ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ë²•ì  ê·¼ê±°Â·ì¡°ë¬¸\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼í•©ì˜ì„œ ì‘ì„± í›„ ì´í˜¼ì˜ íš¨ë ¥ì´ ìƒì‹¤ë˜ì—ˆì„ ë•Œ, ì¬ì‚°ë¶„í• ì— ê´€í•œ í•©ì˜ì˜ íš¨ë ¥ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì ˆì°¨Â·ë°©ë²•\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ ë°°ìš°ì ìˆëŠ” ìì™€ ê°„í†µí–‰ìœ„ë¥¼ í•œ ì‚¬ëŒ(ìƒê°„ì)ì€ ë²•ì ìœ¼ë¡œ ì–´ë–¤ ì±…ì„ì´ ìˆë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì œì¬Â·êµ¬ì œìˆ˜ë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„\n",
            "\n",
            "ğŸ—¨ï¸ ë™í˜¸íšŒ í™œë™ ì¤‘ ì•Œê²Œ ëœ ì‚¬ëŒê³¼ ë¶€ì •í–‰ìœ„ê°€ ì‚¬ì‹¤í˜¼ ê´€ê³„ íŒŒíƒ„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ì–´ë–»ê²Œ í‰ê°€ë˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì ˆì°¨Â·ë°©ë²•\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼ ì†Œì†¡ ë¶„ì•¼ì—ì„œ ì¼ë°©ì˜ ë¶€ì •í–‰ìœ„ê°€ ìˆëŠ” ìˆìŒì—ë„ ìœ„ìë£Œ ì²­êµ¬ê°€ ì¸ì •ë˜ì§€ ì•Šì„ ìˆ˜ ìˆëŠ” ê²½ìš°ëŠ”  ë¬´ì—‡ì¸ê°€ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì¦ê±°Â·ì…ì¦\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼ ì†Œì†¡ì—ì„œ ìœ„ìë£Œ ì²­êµ¬ì™€ ìœ„ìë£Œ ì§€ê¸‰ì€ ì–´ë–¤ ê¸°ì¤€ì— ì˜í•´ ê²°ì •ë˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì¦ê±°Â·ì…ì¦\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬\n",
            "\n",
            "ğŸ—¨ï¸ ë¶€ëª¨ê°€ ìë…€ì˜ ì–‘ìœ¡ë¹„ë¥¼ ì§€ê¸‰í•  ì˜ë¬´ë¥¼ ë¶€ì¸í•˜ê¸° ìœ„í•´ ì¦ëª…í•´ì•¼ í•˜ëŠ” ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì¦ê±°Â·ì…ì¦\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ ì–‘ìœ¡ë¹„ ì‚°ì • ê¸°ì¤€ì— ìˆì–´ ë²•ì›ì´ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê¸ˆì•¡Â·ì‚°ì •\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼ì†Œì†¡ì—ì„œ ì¬ì‚°ë¶„í• ì˜ ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê¸ˆì•¡Â·ì‚°ì •\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    \"ë‚¨í¸ì´ ìƒí™œë¹„ë¥¼ ì£¼ì§€ ì•Šê³  ì§‘ì„ ë‚˜ê°”ì–´ìš”. ì´í˜¼ ì‚¬ìœ ê°€ ë ê¹Œìš”?\",\n",
        "    \"ê²°í˜¼ ì „ ëª¨ì€ ëˆë„ ì¬ì‚°ë¶„í•  ëŒ€ìƒì´ ë˜ë‚˜ìš”?\",\n",
        "    \"ë°°ìš°ìê°€ ì œ ëª…ì˜ë¡œ ë¹šì„ ëƒˆì–´ìš”. ì œê°€ ê°šì•„ì•¼ í•˜ë‚˜ìš”?\",\n",
        "    \"ì´í˜¼ ì†Œì†¡ ì¤‘ì— ë‹¤ë¥¸ ì‚¬ëŒì„ ë§Œë‚˜ë©´ ë¬¸ì œê°€ ë˜ë‚˜ìš”?\",\n",
        "    \"ìƒê°„ë…€í•œí…Œ ìœ„ìë£Œ ì²­êµ¬í•˜ë ¤ë©´ ì–´ë–¤ ì¦ê±°ê°€ í•„ìš”í•´ìš”?\",\n",
        "    \"ì•„ì´ ì•„ë¹ ê°€ ì–‘ìœ¡ë¹„ë¥¼ ê³„ì† ì•ˆ ì£¼ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\",\n",
        "    \"í•©ì˜ì´í˜¼ì„ í•˜ê¸°ë¡œ í–ˆëŠ”ë° ìƒëŒ€ê°€ ê°‘ìê¸° ì•ˆ ë‚˜ì˜¤ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
        "    \"ì´í˜¼ íŒê²° í›„ì— ìœ„ìë£Œë¥¼ ì¶”ê°€ë¡œ ì²­êµ¬í•  ìˆ˜ ìˆë‚˜ìš”?\",\n",
        "    \"ê°€ì •í­ë ¥ì´ ìˆì—ˆëŠ”ë° ì¦ê±°ê°€ ì—†ì–´ìš”. ì´í˜¼ ê°€ëŠ¥í• ê¹Œìš”?\",\n",
        "    \"ìƒê°„ë‚¨ì´ ê²°í˜¼í•œ ì‚¬ì‹¤ì„ ëª°ëë‹¤ê³  í•˜ë©´ ì±…ì„ì´ ì—†ë‚˜ìš”?\",\n",
        "    \"ì´í˜¼ í›„ì— ì•„ì´ ì„±ì„ ë°”ê¾¸ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\",\n",
        "    \"ë²•ì› ì¡°ì • ì ˆì°¨ê°€ ê¼­ í•„ìš”í•œê°€ìš”?\",\n",
        "    \"ì´í˜¼ í›„ì—ë„ ë‚¨í¸ì´ ì €ë¥¼ ìŠ¤í† í‚¹í•˜ë©´ ì²˜ë²Œí•  ìˆ˜ ìˆë‚˜ìš”?\",\n",
        "    \"ë‚¨í¸ì´ ì œ ëª…ì˜ë¡œ ëœ ì¬ì‚°ì„ ëª°ë˜ íŒ”ì•˜ì–´ìš”. ëŒë ¤ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?\",\n",
        "    \"ì•„ë‚´ê°€ ì™¸ë„í–ˆëŠ”ë° ì¦ê±°ê°€ ì¹´í†¡ë¿ì´ì—ìš”. ìœ„ìë£Œ ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?\",\n",
        "    \"ìƒëŒ€ë°©ì´ ìœ„ìë£Œë¥¼ ì£¼ê¸°ë¡œ ì•½ì†í–ˆëŠ”ë° ì•ˆ ì§€ì¼œìš”. ê°•ì œì§‘í–‰ ê°€ëŠ¥í• ê¹Œìš”?\",\n",
        "    \"ë³„ê±° ì¤‘ì¸ë° ì´í˜¼ì†Œì†¡ì„ ë¨¼ì € ì œê¸°í•  ìˆ˜ ìˆë‚˜ìš”?\",\n",
        "    \"ê²°í˜¼ìƒí™œì´ ì§§ì•„ë„ ì¬ì‚°ë¶„í•  ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\",\n",
        "    \"ë°°ìš°ìê°€ ì •ì‹ ë³‘ ì§„ë‹¨ì„ ë°›ì•˜ì–´ìš”. ì´í˜¼í•  ìˆ˜ ìˆë‚˜ìš”?\",\n",
        "    \"ë²•ë¥ ìƒ í˜¼ì¸ì‹ ê³ ë§Œ ë˜ì–´ ìˆê³  ì‚¬ì‹¤ìƒ ë³„ê±° ì¤‘ì´ì—ìš”. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
        "]\n",
        "\n",
        "print(\"\\n=== ğŸ” í˜„ì¥í˜• ì§ˆì˜ ì˜ˆì¸¡ ê²°ê³¼ ===\")\n",
        "for q in examples:\n",
        "    intent_pred = intent_model.predict([q])[0]\n",
        "    topic_pred = topic_model.predict([preprocess_text(q)])[0]\n",
        "    print(f\"ğŸ—¨ï¸ {q}\")\n",
        "    print(f\"â¡ï¸ ì˜ë„(law_intent): {intent_pred}\")\n",
        "    print(f\"â¡ï¸ ì£¼ì œ(law_topic): {topic_pred}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-E7Tkszm7Yv",
        "outputId": "6fa337d4-5614-4bf6-c67b-7d32f4c7ffa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ğŸ” í˜„ì¥í˜• ì§ˆì˜ ì˜ˆì¸¡ ê²°ê³¼ ===\n",
            "ğŸ—¨ï¸ ë‚¨í¸ì´ ìƒí™œë¹„ë¥¼ ì£¼ì§€ ì•Šê³  ì§‘ì„ ë‚˜ê°”ì–´ìš”. ì´í˜¼ ì‚¬ìœ ê°€ ë ê¹Œìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ê²°í˜¼ ì „ ëª¨ì€ ëˆë„ ì¬ì‚°ë¶„í•  ëŒ€ìƒì´ ë˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ ë°°ìš°ìê°€ ì œ ëª…ì˜ë¡œ ë¹šì„ ëƒˆì–´ìš”. ì œê°€ ê°šì•„ì•¼ í•˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ë²•ì  ê·¼ê±°Â·ì¡°ë¬¸\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼ ì†Œì†¡ ì¤‘ì— ë‹¤ë¥¸ ì‚¬ëŒì„ ë§Œë‚˜ë©´ ë¬¸ì œê°€ ë˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ë²•ì  ê·¼ê±°Â·ì¡°ë¬¸\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ìƒê°„ë…€í•œí…Œ ìœ„ìë£Œ ì²­êµ¬í•˜ë ¤ë©´ ì–´ë–¤ ì¦ê±°ê°€ í•„ìš”í•´ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì¦ê±°Â·ì…ì¦\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬\n",
            "\n",
            "ğŸ—¨ï¸ ì•„ì´ ì•„ë¹ ê°€ ì–‘ìœ¡ë¹„ë¥¼ ê³„ì† ì•ˆ ì£¼ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì ˆì°¨Â·ë°©ë²•\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ í•©ì˜ì´í˜¼ì„ í•˜ê¸°ë¡œ í–ˆëŠ”ë° ìƒëŒ€ê°€ ê°‘ìê¸° ì•ˆ ë‚˜ì˜¤ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì ˆì°¨Â·ë°©ë²•\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼ íŒê²° í›„ì— ìœ„ìë£Œë¥¼ ì¶”ê°€ë¡œ ì²­êµ¬í•  ìˆ˜ ìˆë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì¦ê±°Â·ì…ì¦\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬\n",
            "\n",
            "ğŸ—¨ï¸ ê°€ì •í­ë ¥ì´ ìˆì—ˆëŠ”ë° ì¦ê±°ê°€ ì—†ì–´ìš”. ì´í˜¼ ê°€ëŠ¥í• ê¹Œìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì¦ê±°Â·ì…ì¦\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ìƒê°„ë‚¨ì´ ê²°í˜¼í•œ ì‚¬ì‹¤ì„ ëª°ëë‹¤ê³  í•˜ë©´ ì±…ì„ì´ ì—†ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼ í›„ì— ì•„ì´ ì„±ì„ ë°”ê¾¸ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì ˆì°¨Â·ë°©ë²•\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ë²•ì› ì¡°ì • ì ˆì°¨ê°€ ê¼­ í•„ìš”í•œê°€ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì ˆì°¨Â·ë°©ë²•\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ì´í˜¼ í›„ì—ë„ ë‚¨í¸ì´ ì €ë¥¼ ìŠ¤í† í‚¹í•˜ë©´ ì²˜ë²Œí•  ìˆ˜ ìˆë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì œì¬Â·êµ¬ì œìˆ˜ë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ë‚¨í¸ì´ ì œ ëª…ì˜ë¡œ ëœ ì¬ì‚°ì„ ëª°ë˜ íŒ”ì•˜ì–´ìš”. ëŒë ¤ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ ì•„ë‚´ê°€ ì™¸ë„í–ˆëŠ”ë° ì¦ê±°ê°€ ì¹´í†¡ë¿ì´ì—ìš”. ìœ„ìë£Œ ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì¦ê±°Â·ì…ì¦\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬\n",
            "\n",
            "ğŸ—¨ï¸ ìƒëŒ€ë°©ì´ ìœ„ìë£Œë¥¼ ì£¼ê¸°ë¡œ ì•½ì†í–ˆëŠ”ë° ì•ˆ ì§€ì¼œìš”. ê°•ì œì§‘í–‰ ê°€ëŠ¥í• ê¹Œìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì¦ê±°Â·ì…ì¦\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬\n",
            "\n",
            "ğŸ—¨ï¸ ë³„ê±° ì¤‘ì¸ë° ì´í˜¼ì†Œì†¡ì„ ë¨¼ì € ì œê¸°í•  ìˆ˜ ìˆë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê¸°ê°„Â·ì‹œíš¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ê²°í˜¼ìƒí™œì´ ì§§ì•„ë„ ì¬ì‚°ë¶„í•  ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)\n",
            "\n",
            "ğŸ—¨ï¸ ë°°ìš°ìê°€ ì •ì‹ ë³‘ ì§„ë‹¨ì„ ë°›ì•˜ì–´ìš”. ì´í˜¼í•  ìˆ˜ ìˆë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n",
            "ğŸ—¨ï¸ ë²•ë¥ ìƒ í˜¼ì¸ì‹ ê³ ë§Œ ë˜ì–´ ìˆê³  ì‚¬ì‹¤ìƒ ë³„ê±° ì¤‘ì´ì—ìš”. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\n",
            "â¡ï¸ ì˜ë„(law_intent): ì ˆì°¨Â·ë°©ë²•\n",
            "â¡ï¸ ì£¼ì œ(law_topic): ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from konlpy.tag import Okt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”\n",
        "okt = Okt()\n",
        "# âœ… 1ï¸âƒ£ í˜•íƒœì†Œ ë‹¨ìœ„ tokenizer í•¨ìˆ˜\n",
        "def tokenize_okt(text):\n",
        "    return [token for token, pos in okt.pos(text, stem=True)\n",
        "            if pos not in ['Josa', 'Eomi', 'Punctuation']]  # ì¡°ì‚¬, ì–´ë¯¸ ì œê±°\n",
        "\n",
        "\n",
        "# âœ… 3ï¸âƒ£ TF-IDF ë²¡í„°í™”\n",
        "vectorizer = TfidfVectorizer(\n",
        "    tokenizer=tokenize_okt,       # ğŸ”¥ í˜•íƒœì†Œ ë¶„ì„ê¸° ì—°ê²°\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=3000,\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(df[\"input\"])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# âœ… 4ï¸âƒ£ í† í”½ë³„ í‚¤ì›Œë“œ ë½‘ê¸°\n",
        "def get_top_keywords_per_topic(df, X, label_col, n_keywords=15):\n",
        "    topics = {}\n",
        "    for topic in df[label_col].unique():\n",
        "        idx = df[df[label_col] == topic].index\n",
        "        topic_tfidf = X[idx].mean(axis=0)\n",
        "        top_indices = topic_tfidf.A1.argsort()[::-1][:n_keywords]\n",
        "        topics[topic] = [feature_names[i] for i in top_indices]\n",
        "    return topics\n",
        "\n",
        "topic_keywords = get_top_keywords_per_topic(df, X, 'topic_name', 15)\n",
        "\n",
        "# âœ… 5ï¸âƒ£ ê²°ê³¼ ì¶œë ¥\n",
        "for topic, keywords in topic_keywords.items():\n",
        "    print(f\"\\n=== ğŸ·ï¸ {topic} ===\")\n",
        "    print(\", \".join(keywords))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGLitysdHzcA",
        "outputId": "f505ce6c-d755-4a23-9470-d734536943fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ğŸ·ï¸ ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬ ===\n",
            "ìœ„ìë£Œ, ì²­êµ¬, ì†í•´ë°°ìƒ, ë¶€ì •í–‰ìœ„, í•˜ë‹¤, ì†í•´ë°°ìƒ ì²­êµ¬, ì¸í•˜ë‹¤, ë¬´ì—‡, ì , ì •ì‹ , ì •ì‹  ì , ë¶€ì •í–‰ìœ„ ì¸í•˜ë‹¤, ìœ„ìë£Œ ì²­êµ¬, ë˜ë‹¤, ë°°ìš°ì\n",
            "\n",
            "=== ğŸ·ï¸ ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±° ===\n",
            "ì´í˜¼, ë˜ë‹¤, ì–´ë–»ë‹¤, ìˆë‹¤, í•˜ë‹¤, í•˜ë‚˜ìš”, ì‹œíš¨, ì‚¬ìœ , ì¦ê±°, ë¬´ì—‡, ë²•ì , ì†Œì†¡, ì´í˜¼ ì‚¬ìœ , ì¸ì •, ë²•ì›\n",
            "\n",
            "=== ğŸ·ï¸ ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„ ===\n",
            "ì œ, 3, ì œ 3, í•˜ë‹¤, ë¶€ì •í–‰ìœ„, ì±…ì„, ë¶€ë¶€, 3 ìê°€, ìê°€, ê²½ìš°, ë¬´ì—‡, ë˜ë‹¤, ë¶€ì •í–‰ìœ„ í•˜ë‹¤, ì†í•´ë°°ìƒ ì±…ì„, ì¡°ê±´\n",
            "\n",
            "=== ğŸ·ï¸ ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„) ===\n",
            "ì¬ì‚°, ì¬ì‚° ë¶„í• , ë¶„í• , ì–‘ìœ¡ë¹„, ë˜ë‹¤, ìˆë‹¤, ì–´ë–»ë‹¤, í•˜ë‹¤, ì´í˜¼, ë¬´ì—‡, ë¶„í•  ì²­êµ¬, ì²­êµ¬, ì‹œ, í›„, ë”°ë¥´ë‹¤\n",
            "\n",
            "=== ğŸ·ï¸ ì¼ë°˜ ìƒë‹´Â·ìƒí™© ë¬¸ì˜ (ë¹„ë²•ë¥ ì  ì§ˆë¬¸) ===\n",
            "ìƒë‹´, ë°›ë‹¤, ìˆë‹¤, ìƒë‹´ ë°›ë‹¤, ìˆ˜ ìˆë‹¤, ìˆ˜, ë°›ë‹¤ ìˆ˜, ê°€ëŠ¥í•˜ë‹¤, í•˜ë‹¤, ë˜ë‹¤, ë²•ë¥  ìƒë‹´, ìƒë‹´ ì¤‘, ìƒë‹´ í›„, í›„, ì´í˜¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 2ï¸âƒ£ TF-IDFìš© í† í¬ë‚˜ì´ì € í•¨ìˆ˜\n",
        "# --------------------------\n",
        "from konlpy.tag import Okt\n",
        "import re\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "def tokenize_okt(text):\n",
        "    \"\"\"ì •ì œ + í˜•íƒœì†Œ ë¶„ì„ + ì¤‘ë³µ ìµœì†Œí™” ë²„ì „\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "\n",
        "    # 0ï¸âƒ£ ì œ3ì ë³€í˜• í†µí•©\n",
        "    text = re.sub(r'ì œ\\s*\\d+\\s*ì', lambda m: m.group(0).replace(\" \", \"\"), text)\n",
        "\n",
        "    # 1ï¸âƒ£ íŠ¹ìˆ˜ë¬¸ì ì œê±° (ìˆ«ì ìœ ì§€)\n",
        "    text = re.sub('[^0-9ã„±-ã…ã…-ã…£ê°€-í£ ]', '', text)\n",
        "\n",
        "    # 2ï¸âƒ£ í˜•íƒœì†Œ ë¶„ì„ (ì–´ê°„ ë³µì›)\n",
        "    tokens = okt.morphs(text, stem=True)\n",
        "\n",
        "    # 3ï¸âƒ£ â€œì œ3ìâ€ í•©ì¹˜ê¸° ë³´ì •\n",
        "    merged_tokens = []\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        if (\n",
        "            i + 2 < len(tokens)\n",
        "            and tokens[i] == \"ì œ\"\n",
        "            and tokens[i + 1].isdigit()\n",
        "            and tokens[i + 2] == \"ì\"\n",
        "        ):\n",
        "            merged_tokens.append(f\"ì œ{tokens[i+1]}ì\")\n",
        "            i += 3\n",
        "        else:\n",
        "            merged_tokens.append(tokens[i])\n",
        "            i += 1\n",
        "\n",
        "    # 4ï¸âƒ£ ë¶ˆìš©ì–´ ì œê±° + ë²•ë¥ í‚¤ì›Œë“œ ë³´ì¡´\n",
        "    filtered = []\n",
        "    for t in merged_tokens:\n",
        "        if t in LEGAL_KEYWORDS:  # ë²•ë¥  í‚¤ì›Œë“œë©´ ë¬´ì¡°ê±´ ì‚´ë¦¼\n",
        "            filtered.append(t)\n",
        "        elif t not in MINIMAL_STOPWORDS and len(t) > 1:\n",
        "            filtered.append(t)\n",
        "\n",
        "    # 5ï¸âƒ£ ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)\n",
        "    final_tokens = list(dict.fromkeys(filtered))\n",
        "\n",
        "    return final_tokens\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    tokenizer=tokenize_okt,    # â† ìš°ë¦¬ê°€ ë§Œë“  í˜•íƒœì†Œ ë¶„ì„ê¸°\n",
        "    token_pattern=None,        # â† ì •ê·œì‹ ë„ê¸° (ì•ˆ ë„ë©´ ë˜ ìª¼ê°¬)\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=3000\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(df1[\"input_processed\"])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "# ==============================\n",
        "# 3ï¸âƒ£ í† í”½ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜\n",
        "# ==============================\n",
        "def get_top_keywords_per_topic(df, X, label_col, n_keywords=15):\n",
        "    topics = {}\n",
        "    for topic in df[label_col].unique():\n",
        "        idx = df[df[label_col] == topic].index\n",
        "        topic_tfidf = X[idx].mean(axis=0)\n",
        "        top_indices = topic_tfidf.A1.argsort()[::-1][:n_keywords]\n",
        "        topics[topic] = [feature_names[i] for i in top_indices]\n",
        "    return topics\n",
        "\n",
        "topic_keywords = get_top_keywords_per_topic(df1, X, 'topic_name', 15)"
      ],
      "metadata": {
        "id": "5mnsHDCvoap4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'topic_keywords' in df1.columns:\n",
        "    df1['topic_keywords'] = df1['topic_keywords'].apply(\n",
        "        lambda x: ', '.join(x) if isinstance(x, (list, tuple)) else str(x)\n",
        "    )"
      ],
      "metadata": {
        "id": "VQSbe6e7r2Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_keywords_map = {\n",
        "    'ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±°': [\n",
        "        'ì´í˜¼', 'ë²•ì ', 'ì‚¬ìœ ', 'ì‹œíš¨', 'í˜¼ì¸', 'ì´í˜¼ ì‚¬ìœ ', 'ì†Œì†¡',\n",
        "        'ê¸°ì¤€', 'ì¦ê±°', 'ë²•ì›', 'ì¤‘ë‹¨', 'íŒŒíƒ„', 'íš¨ë ¥', 'ë¶€ì •í–‰ìœ„', 'íŒë‹¨'\n",
        "    ],\n",
        "\n",
        "    'ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬': [\n",
        "        'ìœ„ìë£Œ', 'ì²­êµ¬', 'ì†í•´ë°°ìƒ', 'ë¶€ì •í–‰ìœ„', 'ì†í•´ë°°ìƒ ì²­êµ¬', 'ì •ì‹ ',\n",
        "        'ìœ„ìë£Œ ì²­êµ¬', 'ë°°ìš°ì', 'ë¶€ì •í–‰ìœ„ ì •ì‹ ', 'ë°°ìš°ì ë¶€ì •í–‰ìœ„',\n",
        "        'ì •ì‹  ê³ í†µ', 'ê³ í†µ', 'ë¶€ì •í–‰ìœ„ ì†í•´ë°°ìƒ', 'ê¸°ì¤€', 'ê²°ì •'\n",
        "    ],\n",
        "\n",
        "    'ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„': [\n",
        "        'ì œ3ì', 'ë¶€ì •í–‰ìœ„', 'ì±…ì„', 'ë¶€ë¶€', 'ì¡°ê±´', 'ì†í•´ë°°ìƒ ì±…ì„',\n",
        "        'ë¶ˆë²•í–‰ìœ„', 'ë°°ìš°ì', 'ì†í•´ë°°ìƒ', 'ì¡°ê±´ ì œ3ì', 'ì¼ë°©',\n",
        "        'ë¶€ë¶€ ì¼ë°©', 'ë²•ì ', 'ì¼ë°© ë¶€ì •í–‰ìœ„', 'ìƒí™œ'\n",
        "    ],\n",
        "\n",
        "    'ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„)': [\n",
        "        'ì¬ì‚°', 'ë¶„í• ', 'ì¬ì‚° ë¶„í• ', 'ì–‘ìœ¡ë¹„', 'ì´í˜¼', 'ë¶„í•  ì²­êµ¬',\n",
        "        'ì²­êµ¬', 'ì´í˜¼ ì¬ì‚°', 'ê¸°ì¤€', 'ìë…€', 'ì‚¬ì‹¤í˜¼', 'ë²•ì ',\n",
        "        'ê³ ë ¤', 'ê³„ì‚°', 'ë¹„ìœ¨'\n",
        "    ],\n",
        "\n",
        "    'ì¼ë°˜ ìƒë‹´Â·ìƒí™© ë¬¸ì˜ (ë¹„ë²•ë¥ ì  ì§ˆë¬¸)': [\n",
        "        'ìƒë‹´', 'ë°›ë‹¤', 'ìƒë‹´ ë°›ë‹¤', 'ë²•ë¥  ìƒë‹´', 'ë²•ë¥ ', 'ì´í˜¼',\n",
        "        'ì´í˜¼ ìƒë‹´', 'ì§„í–‰', 'ë°”ë¡œ', 'ê°ì •', 'ì˜ˆì•½', 'ë‹¤ë¥¸',\n",
        "        'ë³€í˜¸ì‚¬', 'ì„œë¥˜', 'ìƒë‹´ ì‹ ì²­'\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "df1['topic_keywords'] = df1['topic_name'].map(topic_keywords_map)"
      ],
      "metadata": {
        "id": "aA8TYSpasKRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì„œ ì €ì¥\n",
        "df1['topic_keywords'] = df1['topic_keywords'].apply(\n",
        "    lambda x: ', '.join(x) if isinstance(x, (list, tuple)) else str(x)\n",
        ")\n"
      ],
      "metadata": {
        "id": "KcX743sssnhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_csv(\"/content/drive/MyDrive/divorce_topic_labeled_with_topic_keywords.csv\", encoding=\"utf-8-sig\", index=False)\n",
        "print(\"âœ… CSV ì €ì¥ ì™„ë£Œ! â†’ law_qa_with_topic_keywords.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UyOv_mSsulF",
        "outputId": "78c55164-60bc-474a-f200-1456bc010e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… CSV ì €ì¥ ì™„ë£Œ! â†’ law_qa_with_topic_keywords.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì½˜ì†” ë¯¸ë¦¬ë³´ê¸°\n",
        "for topic, keywords in topic_keywords.items():\n",
        "    print(f\"\\n=== ğŸ·ï¸ {topic} ===\")\n",
        "    print(\", \".join(keywords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZHe-J-opDQ_",
        "outputId": "fe11959d-c8ee-45af-c44b-34ca01442006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ğŸ·ï¸ ë¶€ì •í–‰ìœ„ì˜ ë²•ë¥ ì  ê·¼ê±° ===\n",
            "ì´í˜¼, ë²•ì , ì‚¬ìœ , ì‹œíš¨, í˜¼ì¸, ì´í˜¼ ì‚¬ìœ , ì†Œì†¡, ê¸°ì¤€, ì¦ê±°, ë²•ì›, ì¤‘ë‹¨, íŒŒíƒ„, íš¨ë ¥, ë¶€ì •í–‰ìœ„, íŒë‹¨\n",
            "\n",
            "=== ğŸ·ï¸ ìœ„ìë£Œ ë° ì†í•´ë°°ìƒ ì²­êµ¬ ===\n",
            "ìœ„ìë£Œ, ì²­êµ¬, ì†í•´ë°°ìƒ, ë¶€ì •í–‰ìœ„, ì†í•´ë°°ìƒ ì²­êµ¬, ì •ì‹ , ìœ„ìë£Œ ì²­êµ¬, ë°°ìš°ì, ë¶€ì •í–‰ìœ„ ì •ì‹ , ë°°ìš°ì ë¶€ì •í–‰ìœ„, ì •ì‹  ê³ í†µ, ê³ í†µ, ë¶€ì •í–‰ìœ„ ì†í•´ë°°ìƒ, ê¸°ì¤€, ê²°ì •\n",
            "\n",
            "=== ğŸ·ï¸ ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„ ===\n",
            "ì œ3ì, ë¶€ì •í–‰ìœ„, ì±…ì„, ë¶€ë¶€, ì¡°ê±´, ì†í•´ë°°ìƒ ì±…ì„, ë¶ˆë²•í–‰ìœ„, ë°°ìš°ì, ì†í•´ë°°ìƒ, ì¡°ê±´ ì œ3ì, ì¼ë°©, ë¶€ë¶€ ì¼ë°©, ë²•ì , ì¼ë°© ë¶€ì •í–‰ìœ„, ìƒí™œ\n",
            "\n",
            "=== ğŸ·ï¸ ì´í˜¼ ì‹œ ê¸ˆì „ ë¬¸ì œ (ì¬ì‚°ë¶„í• Â·ì–‘ìœ¡ë¹„) ===\n",
            "ì¬ì‚°, ë¶„í• , ì¬ì‚° ë¶„í• , ì–‘ìœ¡ë¹„, ì´í˜¼, ë¶„í•  ì²­êµ¬, ì²­êµ¬, ì´í˜¼ ì¬ì‚°, ê¸°ì¤€, ìë…€, ì‚¬ì‹¤í˜¼, ë²•ì , ê³ ë ¤, ê³„ì‚°, ë¹„ìœ¨\n",
            "\n",
            "=== ğŸ·ï¸ ì¼ë°˜ ìƒë‹´Â·ìƒí™© ë¬¸ì˜ (ë¹„ë²•ë¥ ì  ì§ˆë¬¸) ===\n",
            "ìƒë‹´, ë°›ë‹¤, ìƒë‹´ ë°›ë‹¤, ë²•ë¥  ìƒë‹´, ë²•ë¥ , ì´í˜¼, ì´í˜¼ ìƒë‹´, ì§„í–‰, ë°”ë¡œ, ê°ì •, ì˜ˆì•½, ë‹¤ë¥¸, ë³€í˜¸ì‚¬, ì„œë¥˜, ìƒë‹´ ì‹ ì²­\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ìœ„ì²˜ëŸ¼ ê³„ì† ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•˜ì§€ ì•Šê³  topicì„ ë½‘ì•„ë‚´ë‹ˆê¹Œ . ì¡°ì‚¬, ë“±ë“±ì´ í•„ìš”ì—†ëŠ” ê²ƒë“¤ì´ ë‚˜ì˜´\n",
        "# ë‹¨, ì§€ê¸ˆì²˜ëŸ¼ â€œLDA ëª¨ë¸ë§ìš©â€ì´ ì•„ë‹ˆë¼ â€œTF-IDF ë¶„ë¥˜ê¸° ì…ë ¥ ì „ ì „ì²˜ë¦¬ìš©â€ìœ¼ë¡œ ì”€\n",
        "# ì´ë ‡ê²Œ ì ìš©í•˜ë©´ topic í˜¼ë™ ë¬¸ì œ(íŠ¹íˆ â€˜ì´í˜¼â€™, â€˜ë˜ë‹¤â€™ ê°™ì€ ê³µí†µì–´) í•´ê²°ë¨."
      ],
      "metadata": {
        "id": "m8GHuBrYM8Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "# MINIMAL_STOPWORDSì™€ LEGAL_KEYWORDSëŠ” ì œê³µëœ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "MINIMAL_STOPWORDS = list(set([\n",
        "    'ê²ƒ', 'ìˆ˜', 'ë•Œ', 'ë“±', 'ë“¤', 'ë”', 'ì´', 'ê·¸', 'ì €', 'ë‚˜', 'ìš°ë¦¬', 'ê°™', 'ë˜', 'ë§Œ', 'ë…„', 'ì›”', 'ì¼', 'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤',\n",
        "    'ê°€ëŠ¥í•˜ë‹¤', 'ê°€ëŠ¥', 'ê°€ë‹¤', 'ë˜ë‹¤', 'í•˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'ì•Šë‹¤', 'ëœë‹¤', 'í•œë‹¤', 'ì–´ë–»ê²Œ', 'ì–´ë–¤', 'ë¬´ì—‡', 'ì–¸ì œ', 'ì–´ë””ì„œ', 'ì™œ', 'ëˆ„ê°€', 'ì–¼ë§ˆ', 'ëª‡',\n",
        "    'ì•Œê³ ', 'ì‹¶ë‹¤', 'ê¶ê¸ˆí•˜ë‹¤', 'ë¬¸ì˜', 'ì§ˆë¬¸', 'ë‹µë³€', 'ì„¤ëª…', 'ì´í•´', 'ê³¼ì •', 'ì ˆì°¨', 'ì´í›„', 'ë‹¤ìŒ', 'ë¨¼ì €', 'ê·¸ë¦¬ê³ ', 'ê·¸ëŸ¬ë‚˜', 'í•˜ì§€ë§Œ', 'ê·¸ë˜ì„œ', 'ì œì','ì œí˜¸','ì œì¡°',\n",
        "    'ì—†', 'ìˆ', 'í•˜', 'ë˜', 'ì•Š', 'ë‚˜', 'ìš°ë¦¬', 'ë„ˆ', 'ë‹¹ì‹ ', 'ê°™', 'ë˜', 'ê²ƒ', 'ë•Œ', 'ë“±', 'ë•Œë¬¸', 'ì •ë„', 'ì‚¬ì‹¤', 'ìƒê°', 'ê²½ìš°', 'ë¬¸ì œ', 'ë°©ë²•', 'ìƒí™©', 'ë‚´ìš©', 'ê²°ê³¼', 'ì‚¬ëŒ',\n",
        "    'í•´ì•¼', 'í•˜ë©´', 'ê²½ìš°', 'ë•ŒëŠ”', 'ì–´ëŠ', 'ë¬´ìŠ¨', 'ì–´ë””', 'ëˆ„êµ¬' , ' ê°€ì§€ë‹¤' , 'ê°€ì§€','í•˜ë‚˜ìš”', 'ìœ„í•´', 'ì´í˜¼',\n",
        "    'ëŒ€í•œ', 'ê´€ë ¨', 'ë”°ë¥´ë‹¤', 'ì¸ì •', 'ì„±ë¦½', 'ë°œìƒ', 'ì£¼ì¥', 'ë˜ë‚˜ìš”', 'ìˆë‚˜ìš”', 'ì¸ê°€ìš”', 'í• ê¹Œìš”', 'ë˜ë‚˜', 'ìˆë‚˜'\n",
        "]))\n",
        "\n",
        "LEGAL_KEYWORDS = [\n",
        "    'ìœ„ìë£Œ', 'ì¬ì‚°ë¶„í• ', 'ì–‘ìœ¡ê¶Œ', 'ì¹œê¶Œ', 'ë©´ì ‘êµì„­', 'í˜‘ì˜ì´í˜¼', 'ì²­êµ¬', 'ë°°ìƒ', 'ì†í•´', 'ì±…ì„',\n",
        "    'ì°¨ìš©ê¸ˆ', 'ë°˜í™˜', 'ì·¨ì†Œ', 'ì›ìƒíšŒë³µ', 'ì‚¬í•´í–‰ìœ„', 'ì±„ê¶Œì', 'ë°°ìš°ì', 'ì´í˜¼ì‚¬ìœ ', 'ì´í˜¼', 'ì‚¬ìœ ', 'ì¦ëª…', 'ê·¼ê±°', 'ì¡°ê±´', 'ìš”ê±´','ê¸°ì¤€','ìš”ì†Œ','ë²”ìœ„','ì˜ë¬´','íš¨ë ¥','ì ìš©','íŒë‹¨',\n",
        "    'í˜¼ì¸', 'ê¸ˆì „ê±°ë˜', 'ì²­êµ¬ê¶Œ', 'ì•¡ìˆ˜', 'ì •í•´ì§€', 'ë¶€ì ë²•', 'í˜¼ì¸íŒŒíƒ„', 'íŒŒíƒ„', 'ë¶„í• ', 'ì–‘ìœ¡ë¹„', 'ë©´ì ‘',\n",
        "    'êµì„­', 'í˜‘ì˜', 'ì¡°ì •ì‹ ì²­', 'ì†í•´ë°°ìƒ', 'ë¶€ë¶€', 'ë°°ìš°ì', 'ë‹¹ì‚¬ì', 'ì‚¬ëŒ', 'ê°œì¸', 'ìƒëŒ€ë°©',\"ì…ì¦\"\n",
        "]\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    protected_matches = {}\n",
        "\n",
        "    def protect_term(match):\n",
        "        # 'ì œ3ìê°€' ê°™ì€ ë‹¨ì–´ë¥¼ ì°¾ìœ¼ë©´, ì¼ë‹¨ ê·¸ëŒ€ë¡œ ë‘ê³  ê¸°ë¡ë§Œ í•´ë‘ \n",
        "        original_word = match.group(0)\n",
        "        # ê³ ìœ  í† í°ì„ ë§Œë“¤ í•„ìš” ì—†ì´, ì›ë³¸ ë‹¨ì–´ ìì²´ë¥¼ ê¸°ë¡\n",
        "        if original_word not in protected_matches:\n",
        "            protected_matches[original_word] = True\n",
        "        return original_word\n",
        "\n",
        "    def strip_josa(text):\n",
        "        # ë³´í˜¸í•´ì•¼ í•  íŠ¹ì • íŒ¨í„´ (ì˜ˆ: 'ìì˜ ì˜ë¬´')ì´ ìˆìœ¼ë©´ ì¡°ì‚¬ë¥¼ ì œê±°í•˜ì§€ ì•ŠìŒ\n",
        "        preserve_patterns = [\n",
        "            r'ìì˜\\s*ì˜ë¬´', r'ì˜\\s*ë²•ì ', r'ì˜\\s*íš¨ë ¥', r'ì˜\\s*ì±…ì„', r'ì˜\\s*ê·¼ê±°',\n",
        "            r'ì˜\\s*ì„±ê²©', r'ì˜\\s*ì˜ë¯¸', r'ì˜\\s*ê°œë…'\n",
        "        ]\n",
        "        for pattern in preserve_patterns:\n",
        "            if re.search(pattern, text):\n",
        "                return text\n",
        "\n",
        "        # 'ì œ3ì', 'ë°°ìš°ì' ë“± í•µì‹¬ ë‹¨ì–´ ë’¤ì— ë¶™ì€ ì¡°ì‚¬ë¥¼ ë¨¼ì € ì œê±°\n",
        "        # 'ë¥¼' ì¡°ì‚¬ ì¶”ê°€\n",
        "        text = re.sub(r'(ì œ\\d+ì|ë°°ìš°ì|ì¹œê¶Œì|ì²­êµ¬ì|ìƒëŒ€ë°©|ë¶€ë¶€|í˜¼ì¸|ì •ì¡°ì˜ë¬´|ë¶€ì–‘ì˜ë¬´)(ì˜|ê°€|ëŠ”|ì€|ì„|ë¥¼|ì™€|ê³¼)$', r'\\1', text)\n",
        "\n",
        "        # ì¼ë°˜ì ì¸ ëª…ì‚¬ ë’¤ ì¡°ì‚¬ ì œê±°\n",
        "        return re.sub(r'([0-9ê°€-í£]{2,})(ì˜|ê°€|ë¥¼|ì€|ëŠ”|ê³¼|ì™€)$', r'\\1', text)\n",
        "\n",
        "    # 1ë‹¨ê³„: 'ì œìˆ«ì+ë‹¨ì–´' í˜•íƒœ(ì˜ˆ: ì œ3ì, ì œ3ìê°€)ë¥¼ ë¯¸ë¦¬ ì°¾ì•„ ê¸°ë¡\n",
        "    text = re.sub(r'(ì œ\\d+[ê°€-í£]+)', protect_term, text)\n",
        "\n",
        "    # 2ë‹¨ê³„: íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
        "    text = re.sub('[^ã„±-ã…ã…-ã…£ê°€-í£ ]', '', text)\n",
        "\n",
        "    # 3ë‹¨ê³„: í˜•íƒœì†Œ ë¶„ì„\n",
        "    okt = Okt()\n",
        "    word_tokens = okt.pos(text, stem=True)\n",
        "\n",
        "    meaningful_words = []\n",
        "\n",
        "    # 4ë‹¨ê³„: ë‹¨ì–´ í•„í„°ë§\n",
        "    for word, pos in word_tokens:\n",
        "        if word in LEGAL_KEYWORDS:\n",
        "            meaningful_words.append(word)\n",
        "        elif pos in ['Noun', 'Verb'] and len(word) > 1:\n",
        "            token = strip_josa(word) # í˜•íƒœì†Œ ë¶„ì„ëœ ë‹¨ì–´ì—ì„œ ì¡°ì‚¬ ì œê±°\n",
        "            if token not in MINIMAL_STOPWORDS:\n",
        "                meaningful_words.append(token)\n",
        "\n",
        "    # 5ë‹¨ê³„: ë³´í˜¸í–ˆë˜ ë‹¨ì–´ ì²˜ë¦¬ (ğŸš¨í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ğŸš¨)\n",
        "    # ì´ ë‹¨ê³„ì—ì„œëŠ” 'ì œ3ìê°€'ì™€ ê°™ì€ ë‹¨ì–´ê°€ ëª©ë¡ì— ìˆì—ˆë‹¤ë©´,\n",
        "    # ì¡°ì‚¬ ì œê±° í•¨ìˆ˜ë¥¼ ê±°ì³ì„œ 'ì œ3ì'ë¡œ ë§Œë“¤ì–´ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "    for original_term in protected_matches.keys():\n",
        "        processed_term = strip_josa(original_term)\n",
        "        if processed_term not in meaningful_words: # ì¤‘ë³µ ë°©ì§€\n",
        "             meaningful_words.append(processed_term)\n",
        "\n",
        "    # 6ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ìƒì„± (ìˆœì„œ ìœ ì§€ë¥¼ ìœ„í•´ dict.fromkeys ì‚¬ìš©)\n",
        "    final_words = list(dict.fromkeys(meaningful_words))\n",
        "\n",
        "    return ' '.join(final_words)\n",
        "df_clean2['input_processed'] = df_clean2['input'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "LvIwwAmKX8zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê²°ê³¼ ë¹„êµë¥¼ ìœ„í•´ ì›ë³¸ê³¼ ì²˜ë¦¬ëœ ê²°ê³¼ë¥¼ ë‚˜ë€íˆ ì¶œë ¥\n",
        "print(\"\\n=== ì „ì²˜ë¦¬ ì „/í›„ ë¹„êµ ===\")\n",
        "for i in range(5):\n",
        "    print(f\"ì›ë³¸ [{i}]: {df_clean2['input'].iloc[i]}\")\n",
        "    print(f\"ê²°ê³¼ [{i}]: {df_clean2['input_processed'].iloc[i]}\\n\")\n",
        "\n",
        "\n",
        "# ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„ í™•ì¸\n",
        "print(\"=== ê° ëª©ì ì— ë§ê²Œ ìƒì„±ëœ ì „ì²˜ë¦¬ ì»¬ëŸ¼ë“¤ ===\")\n",
        "print(df_clean2[['input', 'input_processed']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6DWGxiAYotc",
        "outputId": "d1a62a6a-41dc-4c55-a8ea-d44cdd3ad7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ì „ì²˜ë¦¬ ì „/í›„ ë¹„êµ ===\n",
            "ì›ë³¸ [0]: ë¶€ì •í–‰ìœ„ì˜ ë²•ì  ì •ì˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
            "ê²°ê³¼ [0]: ë¶€ì •í–‰ìœ„ ë²•ì  ì •ì˜\n",
            "\n",
            "ì›ë³¸ [1]: ì´í˜¼ ì‚¬ìœ ì˜ ë²”ìœ„ëŠ” ì–´ë””ê¹Œì§€ì¸ê°€ìš”?\n",
            "ê²°ê³¼ [1]: ì´í˜¼ ì‚¬ìœ  ë²”ìœ„\n",
            "\n",
            "ì›ë³¸ [2]: ìœ„ìë£Œì˜ ë³¸ì§ˆì€ ì²˜ë²Œì¸ê°€ìš”, ë³´ìƒì¸ê°€ìš”?\n",
            "ê²°ê³¼ [2]: ìœ„ìë£Œ ë³¸ì§ˆ ì²˜ë²Œ ë³´ìƒ\n",
            "\n",
            "ì›ë³¸ [3]: ì •ì‹ ì  ì†í•´ë°°ìƒì˜ ë²•ì  ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
            "ê²°ê³¼ [3]: ì •ì‹  ì†í•´ë°°ìƒ ë²•ì  ê¸°ì¤€\n",
            "\n",
            "ì›ë³¸ [4]: í˜¼ì¸ì˜ ë³¸ì§ˆì  ì˜ë¬´ì—ëŠ” ì–´ë–¤ ê²ƒì´ í¬í•¨ë˜ë‚˜ìš”?\n",
            "ê²°ê³¼ [4]: í˜¼ì¸ ë³¸ì§ˆ ì˜ë¬´ í¬í•¨\n",
            "\n",
            "=== ê° ëª©ì ì— ë§ê²Œ ìƒì„±ëœ ì „ì²˜ë¦¬ ì»¬ëŸ¼ë“¤ ===\n",
            "                       input input_processed\n",
            "0        ë¶€ì •í–‰ìœ„ì˜ ë²•ì  ì •ì˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?      ë¶€ì •í–‰ìœ„ ë²•ì  ì •ì˜\n",
            "1        ì´í˜¼ ì‚¬ìœ ì˜ ë²”ìœ„ëŠ” ì–´ë””ê¹Œì§€ì¸ê°€ìš”?        ì´í˜¼ ì‚¬ìœ  ë²”ìœ„\n",
            "2     ìœ„ìë£Œì˜ ë³¸ì§ˆì€ ì²˜ë²Œì¸ê°€ìš”, ë³´ìƒì¸ê°€ìš”?    ìœ„ìë£Œ ë³¸ì§ˆ ì²˜ë²Œ ë³´ìƒ\n",
            "3    ì •ì‹ ì  ì†í•´ë°°ìƒì˜ ë²•ì  ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?   ì •ì‹  ì†í•´ë°°ìƒ ë²•ì  ê¸°ì¤€\n",
            "4  í˜¼ì¸ì˜ ë³¸ì§ˆì  ì˜ë¬´ì—ëŠ” ì–´ë–¤ ê²ƒì´ í¬í•¨ë˜ë‚˜ìš”?     í˜¼ì¸ ë³¸ì§ˆ ì˜ë¬´ í¬í•¨\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean2.loc[103]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "MRotiwalS45p",
        "outputId": "6c7d9ed9-90fe-4837-c772-d5fdb6579500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "input                                                                                                                                   ë¶ˆë²•í–‰ìœ„ë¡œ ì¸í•œ ì†í•´ë°°ìƒ ì±…ì„ì„ í”¼í•˜ê¸° ìœ„í•´ ì œ3ìê°€ ì¦ëª…í•´ì•¼ í•˜ëŠ” ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
              "intent_name                                                                                                                                                                        ì¦ê±°Â·ì…ì¦\n",
              "intent_label                                                                                                                                                                         NaN\n",
              "topic_name                                                                                                                                                              ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„\n",
              "law_topic                                                                                                                                                                              2\n",
              "output               ì œ3ìê°€ ë¶ˆë²•í–‰ìœ„ë¡œ ì¸í•œ ì†í•´ë°°ìƒ ì±…ì„ì„ í”¼í•˜ê¸° ìœ„í•´ì„œëŠ” ë¶€ì •í–‰ìœ„ ë‹¹ì‹œ ìƒëŒ€ë°©ì´ ì •ìƒì ìœ¼ë¡œ í˜¼ì¸ê´€ê³„ë¥¼ ìœ ì§€í•˜ëŠ” ë°°ìš°ìê°€ ìˆìŒì„ ëª°ëê±°ë‚˜ ì•Œ ìˆ˜ ì—†ì—ˆë‹¤ëŠ” ì ì„ ì¦ëª…í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìƒëŒ€ë°©ìœ¼ë¡œë¶€í„° ë°°ìš°ìê°€ ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ê·¸ëŸ° ì‚¬ì‹¤ì„ ì€íí–ˆê±°ë‚˜ ì†ì˜€ë‹¤ëŠ” ê²ƒì„ ì¦ëª…í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
              "is_divorce                                                                                                                                                                           1.0\n",
              "topic_probability                                                                                                                                                               0.883175\n",
              "announce_date                                                                                                                                              2021-08-11T09:00:00.000+09:00\n",
              "law_intent                                                                                                                                                                             2\n",
              "input_processed                                                                                                                                                   ë¶ˆë²•í–‰ìœ„ ì†í•´ë°°ìƒ ì±…ì„ ì¦ëª… ì¡°ê±´ ì œ3ì\n",
              "Name: 103, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>103</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>input</th>\n",
              "      <td>ë¶ˆë²•í–‰ìœ„ë¡œ ì¸í•œ ì†í•´ë°°ìƒ ì±…ì„ì„ í”¼í•˜ê¸° ìœ„í•´ ì œ3ìê°€ ì¦ëª…í•´ì•¼ í•˜ëŠ” ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intent_name</th>\n",
              "      <td>ì¦ê±°Â·ì…ì¦</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intent_label</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_name</th>\n",
              "      <td>ë¶€ì •í–‰ìœ„ ë° ì œ3ì ê°œì… ì±…ì„</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>law_topic</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>output</th>\n",
              "      <td>ì œ3ìê°€ ë¶ˆë²•í–‰ìœ„ë¡œ ì¸í•œ ì†í•´ë°°ìƒ ì±…ì„ì„ í”¼í•˜ê¸° ìœ„í•´ì„œëŠ” ë¶€ì •í–‰ìœ„ ë‹¹ì‹œ ìƒëŒ€ë°©ì´ ì •ìƒì ìœ¼ë¡œ í˜¼ì¸ê´€ê³„ë¥¼ ìœ ì§€í•˜ëŠ” ë°°ìš°ìê°€ ìˆìŒì„ ëª°ëê±°ë‚˜ ì•Œ ìˆ˜ ì—†ì—ˆë‹¤ëŠ” ì ì„ ì¦ëª…í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìƒëŒ€ë°©ìœ¼ë¡œë¶€í„° ë°°ìš°ìê°€ ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ê·¸ëŸ° ì‚¬ì‹¤ì„ ì€íí–ˆê±°ë‚˜ ì†ì˜€ë‹¤ëŠ” ê²ƒì„ ì¦ëª…í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_divorce</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_probability</th>\n",
              "      <td>0.883175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>announce_date</th>\n",
              "      <td>2021-08-11T09:00:00.000+09:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>law_intent</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>input_processed</th>\n",
              "      <td>ë¶ˆë²•í–‰ìœ„ ì†í•´ë°°ìƒ ì±…ì„ ì¦ëª… ì¡°ê±´ ì œ3ì</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    }
  ]
}