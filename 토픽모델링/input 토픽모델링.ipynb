{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3299a35d-d859-4825-8f44-4bfa98a38c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "# 텍스트 데이터를 머신러닝 알고리즘이 처리할 수 있는 수치 벡터로 변환\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import re\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eed3811-7965-4e5a-806b-2fa9b77f1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/82105/Downloads/divorce_df.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d38453-a3dc-409a-9e88-f9261687ed2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 이혼 관련 문서만 토픽 모델링 시작 ===\n",
      "📊 데이터 분할:\n",
      "  • 이혼 관련 문서: 741개\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 이혼 관련 문서만 토픽 모델링 시작 ===\")\n",
    "\n",
    "print(f\"📊 데이터 분할:\")\n",
    "print(f\"  • 이혼 관련 문서: {len(df)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002ed267-6d92-41dd-a0e1-15daef9f45ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 데이터 전처리: null 값 제거 ===\n",
      "전처리 전 데이터 수: 741\n",
      "null 값 제거 후 데이터 수: 711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 데이터 전처리: null 값 제거 ===\")\n",
    "print(f\"전처리 전 데이터 수: {len(df)}\")\n",
    "\n",
    "# null 값이 있는 행 제거\n",
    "df_clean = df.dropna(subset=['input']).copy()\n",
    "print(f\"null 값 제거 후 데이터 수: {len(df_clean)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027afcd4-523e-47a5-a33c-74eb87470cec",
   "metadata": {},
   "source": [
    "# 1단계 : KoNLPy를 사용한 정교한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4bbc0a0-e502-46ef-897a-c998504a7f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMAL_STOPWORDS = [\n",
    "    '것', '수', '때', '등', '들', '더', '이', '그', '저', '나', \n",
    "    '우리', '같', '또', '만', '년', '월', '일', '하다', '있다', '되다',\n",
    "\n",
    "     '가능하다', '가능', '가다', '되다', '하다', '있다', '없다', '않다', '된다', '한다',\n",
    "    '어떻게', '어떤', '무엇', '언제', '어디서', '왜', '누가', '얼마', '몇',\n",
    "    '알고', '싶다', '궁금하다', '문의', '질문', '답변', '설명', '이해',\n",
    "    '과정', '절차', '이후', '다음', '먼저', '그리고', '그러나', '하지만', '그래서', '제자','제호','제조',\n",
    "\n",
    "     '없', '있', '하', '되', '않', \n",
    "    '나', '우리', '너', '당신', '같', '또', '것', '때', '등', \n",
    "    '때문', '정도', '사실', '생각', '경우', '문제', '방법', '상황', '내용', '결과', '사람',\n",
    "\n",
    "    '해야', '하면', '경우', '때는', '어느', '무슨', '어디', '누구' , ' 가지다' , '가지''하나요', '위해', '이혼',\n",
    "     '조건', '대한', '관련', '따르다', '판단', '인정', '적용', \n",
    "    '효력', '성립', '발생', '요건', '증명', '근거', '주장'\n",
    "]\n",
    "# 중복 제거 후 사용\n",
    "MINIMAL_STOPWORDS = list(set(MINIMAL_STOPWORDS))\n",
    "\n",
    "# # 법률 전문용어는 무조건 포함\n",
    "LEGAL_KEYWORDS = [ '위자료', '재산분할', '양육권', '친권', '면접교섭', \n",
    "    '협의이혼', '청구', '배상', '손해', '책임',\n",
    "    '차용금', '반환', '취소', '원상회복', '사해행위', '채권자', '배우자', '이혼사유',\n",
    "     '이혼', '사유', \n",
    "    '혼인', '금전거래', '청구권',  '액수', '정해지', '부적법',\n",
    "    '혼인파탄', '파탄', '분할', '양육비', '면접',\n",
    "    '교섭', '협의', '조정신청', '손해배상', '부부', '배우자', '당사자', '사람', '개인', '상대방', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2884f6a6-11a1-4e3e-8cee-7900764c99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):  # 전처리 함수 \n",
    "    \"\"\"\n",
    "    한국어 텍스트를 입력받아 전처리하는 함수:\n",
    "    1. '제3자' 형태의 단어를 임시 토큰으로 보호/복원하여 숫자를 보존.\n",
    "    2. 불필요한 한글 이외의 문자를 제거.\n",
    "    3. 형태소 분석 및 어간 추출.\n",
    "    4. 불용어 및 1글자 단어 제거.\n",
    "    \"\"\"\n",
    "    # 1단계: 한글, 공백을 제외한 모든 문자 제거\n",
    "    # re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', text)는 한글과 공백만 남기고 나머지는 지우라는 의미\n",
    "    # 제숫자 + 한글 글자 + 선택적 조사까지 포함\n",
    "    # 딕셔너리를 함수 내부에 선언하여 매 호출마다 초기화 (핵심 수정 사항)\n",
    "    protected_matches = {}\n",
    "\n",
    "    def protect_term(match):\n",
    "        # 찾은 문자열(예: '제3자')을 고유한 토큰(예: '###TOKEN0###')으로 매핑\n",
    "        token = f\"###TOKEN{len(protected_matches)}###\"\n",
    "        protected_matches[token] = match.group(0)\n",
    "        return match.group(0) # 일단 원본 단어 그대로 둔 채로 형태소 분석 진행\n",
    "    def strip_josa(text):\n",
    "    # 한글 명사 뒤 “의”, “가”, “을” 등 제거\n",
    "        return re.sub(r'([가-힣]+)(의|가|를|은|는|과|와)$', r'\\1', text)\n",
    "    \n",
    "\n",
    "    # 1단계: '제3자' 형태의 단어를 임시 토큰으로 치환하여 보호\n",
    "    re.sub(r'(제\\d+[가-힣]+)', protect_term, text)\n",
    "\n",
    "    # 2단계: 한글, 공백, 보호 토큰의 문자(#)만 남기고 제거\n",
    "    text = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣# ]', '', text)\n",
    "\n",
    "    # 2단계: Okt 형태소 분석기를 이용한 토큰화 및 어간 추출(Stemming)\n",
    "    # okt.pos(text, stem=True)는 문장을 (단어, 품사) 형태로 나누고, '하다', '먹다'처럼 원형으로 만들어줍니다.\n",
    "    # 예: \"먹었었고\" -> ('먹다', 'Verb')\n",
    "    # Okt 형태소 분석기 객체 생성\n",
    "    okt = Okt() \n",
    "    word_tokens = okt.pos(text, stem=True)\n",
    "\n",
    "    # 3단계: 불용어 제거\n",
    "    # 형태소 분석 후 의미 있는 단어만 추출하는 필터링 과정\n",
    "    # 의미를 가지는 명사, 동사, 형용사, 부사 중에서 1글자 이상인 단어만 추출합니다.\n",
    "    # 품사 태그가 'Josa'(조사), 'Eomi'(어미), 'Punctuation'(구두점) 등인 단어들을 제거합니다.\n",
    "    meaningful_words = []\n",
    "    for word, pos in word_tokens:\n",
    "        if word in LEGAL_KEYWORDS:\n",
    "            meaningful_words.append(word)\n",
    "        elif pos in ['Noun','Verb'] and len(word) > 1:\n",
    "            token = strip_josa(word)\n",
    "            if token not in MINIMAL_STOPWORDS:\n",
    "                meaningful_words.append(token)\n",
    "     # 6. 보호된 단어 강제 포함 및 복원 (핵심)\n",
    "    # 보호 목록에 있던 단어들을 강제로 최종 리스트에 추가합니다.\n",
    "    # (이미 리스트에 분해되어 들어갔을 수 있지만, 완벽한 복원을 위해 강제 추가)\n",
    "    for original_term in protected_matches.values():\n",
    "        # '제3자' 자체를 하나의 단어로 명시적으로 추가\n",
    "        meaningful_words.append(original_term)\n",
    "        \n",
    "    # 7. 중복 제거 및 최종 문자열 반환\n",
    "    final_words = list(dict.fromkeys(meaningful_words))\n",
    "    # 최종적으로 공백으로 연결된 문자열을 반환합니다. \n",
    "    # 모델에 따라 리스트 형태(meaningful_words)를 그대로 사용할 수도 있습니다.\n",
    "    # 텍스트에서 분석에 의미 있는 핵심 단어들만 남긴 리스트 생성\n",
    "    return ' '.join(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aa35555-c6d9-42e1-b150-8469f425845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 전처리 전/후 비교 ===\n",
      "원본 [0]: 혼인 중 발생한 금전거래와 관련하여 차용금 반환 청구권이 인정되는 조건은 무엇인가요?\n",
      "결과 [0]: 혼인 금전 거래 차용 반환 청구권\n",
      "\n",
      "원본 [1]: 제3자가 부부의 일방과 부정행위를 할 경우 어떤 법적 책임을 지게 되나요?\n",
      "결과 [1]: 부부 일방 부정행위 법적 책임 지게 제3자가\n",
      "\n",
      "원본 [2]: 민법 제840조 제1호에서 규정한 재판상 이혼사유 중 부정한 행위의 의미는 무엇인가요?\n",
      "결과 [2]: 민법 규정 재판 이혼 사유 부정 행위 의미 제840조 제1호에서\n",
      "\n",
      "원본 [3]: 배우자가 있는 사람과 부정행위를 한 경우 위자료의 액수는 어떻게 정해지나요?\n",
      "결과 [3]: 배우자 부정행위 위자료 액수 정해지다\n",
      "\n",
      "원본 [4]: 사해행위 취소 및 원상회복청구 소송에서 다른 채권자의 청구가 부적법해지는 상황은 어떤 경우인가요?\n",
      "결과 [4]: 사해행위 취소 원상회복 청구 소송 다른 채권자 부적 법해\n",
      "\n",
      "=== 각 목적에 맞게 생성된 전처리 컬럼들 ===\n",
      "                                               input  \\\n",
      "0    혼인 중 발생한 금전거래와 관련하여 차용금 반환 청구권이 인정되는 조건은 무엇인가요?   \n",
      "1          제3자가 부부의 일방과 부정행위를 할 경우 어떤 법적 책임을 지게 되나요?   \n",
      "2   민법 제840조 제1호에서 규정한 재판상 이혼사유 중 부정한 행위의 의미는 무엇인가요?   \n",
      "3         배우자가 있는 사람과 부정행위를 한 경우 위자료의 액수는 어떻게 정해지나요?   \n",
      "4  사해행위 취소 및 원상회복청구 소송에서 다른 채권자의 청구가 부적법해지는 상황은 어...   \n",
      "\n",
      "                       input_processed  \n",
      "0                   혼인 금전 거래 차용 반환 청구권  \n",
      "1             부부 일방 부정행위 법적 책임 지게 제3자가  \n",
      "2  민법 규정 재판 이혼 사유 부정 행위 의미 제840조 제1호에서  \n",
      "3                 배우자 부정행위 위자료 액수 정해지다  \n",
      "4      사해행위 취소 원상회복 청구 소송 다른 채권자 부적 법해  \n"
     ]
    }
   ],
   "source": [
    "# --- 4. 각 목적에 맞게 전처리 컬럼 생성 ---\n",
    "# 질문 의도 파악 모델용: 'input' 컬럼만 전처리\n",
    "# 'input' 컬럼에 전처리 함수를 적용하여 새로운 'input_processed' 컬럼 생성\n",
    "df_clean['input_processed'] = df_clean['input'].apply(preprocess_text)\n",
    "df_clean['combined_processed'] = df_clean['text_combined'].apply(preprocess_text)\n",
    "\n",
    "# 결과 비교를 위해 원본과 처리된 결과를 나란히 출력\n",
    "print(\"\\n=== 전처리 전/후 비교 ===\")\n",
    "for i in range(5):\n",
    "    print(f\"원본 [{i}]: {df_clean['input'].iloc[i]}\")\n",
    "    print(f\"결과 [{i}]: {df_clean['input_processed'].iloc[i]}\\n\")\n",
    "\n",
    "\n",
    "# 전처리된 데이터가 포함된 데이터프레임 확인\n",
    "print(\"=== 각 목적에 맞게 생성된 전처리 컬럼들 ===\")\n",
    "print(df_clean[['input', 'input_processed']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79b279-0c5c-4567-9740-91566cfbc1f8",
   "metadata": {},
   "source": [
    "# 2단계: 최적화된 TF-IDF 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8299e8f5-f277-48e3-a25d-890729661281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 행렬 크기: (711, 411)\n",
      "문서 수: 711\n",
      "특성(단어) 수: 411\n",
      "상위 20개 특성: ['가지다' '가하다' '가하다 법적' '가하다 불법행위' '가하다 손해배상' '간주' '간주 자가' '간통' '개입'\n",
      " '개입 손해배상' '개입 파탄' '개입 혼인' '거래' '겪다' '결정' '결정 고려' '결정 기준' '계산' '계약' '고려']\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorizer 설정\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,      # 상위 빈도 1000개 단어만 사용\n",
    "    min_df=3,\n",
    "    max_df=0.1,           \n",
    "    lowercase=False,         # 소문자 변환 x\n",
    "    ngram_range=(1, 2),     # 1-gram, 2-gram 모두 사용\n",
    "    sublinear_tf=True,            # TF 값에 로그 스케일 적용 (성능 향상)\n",
    "    token_pattern=r'[가-힣]{2,}', # 한글 2글자 이상\n",
    ")\n",
    "\n",
    "# TF-IDF 행렬 생성\n",
    "tfidf_matrix = vectorizer.fit_transform(df_clean['input_processed'])  # X는 (문서 수 × 단어 수) 크기의 희소 행렬\n",
    "\n",
    "print(f\"TF-IDF 행렬 크기: {tfidf_matrix.shape}\")\n",
    "print(f\"문서 수: {tfidf_matrix.shape[0]}\")\n",
    "print(f\"특성(단어) 수: {tfidf_matrix.shape[1]}\")\n",
    "\n",
    "# 특성 이름(단어들) 확인\n",
    "# vectorizer.get_feature_names_out()로 어떤 단어가 벡터에 들어갔는지 확인 가능\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"상위 20개 특성: {feature_names[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d02fadd-958c-4b38-a144-dfe9079c1872",
   "metadata": {},
   "source": [
    "# 3단계: 토픽 개수 최적화\n",
    "# 최적의 토픽 개수를 찾기 위해 여러 지표를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237d3d1-49e1-4b09-92ee-26f09731c1fe",
   "metadata": {},
   "source": [
    "# 더 정확한 토픽 모델링을 위해 Gensim 라이브러리를 사용\n",
    "# 고급 기법: Gensim LDA + Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26837213-0da1-4123-bb8f-62b39ea98d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# 텍스트를 토큰 리스트로 변환\n",
    "texts = [text.split() for text in df_clean['input_processed']]\n",
    "\n",
    "# 1. Bi-gram 모델 생성\n",
    "phrases = Phrases(texts, min_count=5, threshold=10) # min_count, threshold는 데이터에 맞게 조정\n",
    "bigram = Phraser(phrases)\n",
    "\n",
    "# 2. Bi-gram 적용\n",
    "texts_bigram = [bigram[doc] for doc in texts]\n",
    "\n",
    "# (선택) Tri-gram까지 적용하고 싶다면 한 번 더 수행\n",
    "# phrases_tri = Phrases(texts_bigram, min_count=5, threshold=10)\n",
    "# trigram = Phraser(phrases_tri)\n",
    "# texts_trigram = [trigram[doc] for doc in texts_bigram]\n",
    "\n",
    "# 이제 texts_bigram (또는 texts_trigram)을 사용하여 Dictionary와 Corpus를 만드세요.\n",
    "# dictionary = Dictionary(texts_bigram)\n",
    "# corpus = [dictionary.doc2bow(text) for text in texts_bigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf658f0-21de-4f13-9cd5-03a24371ab0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토픽 수 8: Coherence = 0.3599\n",
      "토픽 수 9: Coherence = 0.3655\n",
      "\n",
      "Coherence 상위 3개: [8, 9]\n",
      "\n",
      "=== 8개 토픽 결과 ===\n",
      "토픽 0: 부부, 제3자가, 불법행위, 부정행위, 책임, 생활_침해, 행위, 타인\n",
      "토픽 1: 재산_분할, 청구, 이혼, 양육비, 의무, 부부, 지급, 이루어지다\n",
      "토픽 2: 법적, 부정행위, 책임, 배우자, 제3자가, 부부_일방, 지게, 손해배상\n",
      "토픽 3: 기준, 부정행위, 청구, 위자료, 손해배상, 산정, 결정, 위자료_액수\n",
      "토픽 4: 혼인_관계, 파탄, 공동, 의무, 부부, 생활, 기준, 유지\n",
      "토픽 5: 부정행위, 책임, 제3자가, 손해배상, 부부_일방, 배우자, 불법행위, 재산_분할\n",
      "토픽 6: 손해배상, 부정행위, 청구, 배우자, 정신, 정신_고통, 손해, 범위\n",
      "토픽 7: 부정_행위, 범위, 법률, 이혼, 민법, 배우자, 이혼소송, 평\n",
      "\n",
      "=== 9개 토픽 결과 ===\n",
      "토픽 0: 부부, 책임, 제3자가, 부정행위, 손해배상, 대해, 불법행위, 타인\n",
      "토픽 1: 이혼, 재산_분할, 청구, 양육비, 의무, 지급, 법적, 이루어지다\n",
      "토픽 2: 법적, 부정행위, 책임, 다른, 부부, 제3자는, 파탄_초래, 한쪽\n",
      "토픽 3: 기준, 부정행위, 위자료_액수, 산정, 결정, 사실혼_관계, 손해배상, 청구\n",
      "토픽 4: 부부, 혼인_관계, 파탄, 불법행위, 제3자가, 책임, 행위, 제3자의\n",
      "토픽 5: 부정행위, 제3자가, 책임, 부부_일방, 배우자, 손해배상, 법적, 불법행위\n",
      "토픽 6: 청구, 손해배상, 부정행위, 배우자, 정신_고통, 위자료, 정신, 결정\n",
      "토픽 7: 부정_행위, 민법, 규정, 간통, 권리, 범위, 제840조, 배우자\n",
      "토픽 8: 범위, 손해, 정신, 배상, 법률, 불법행위, 청구, 부정행위\n"
     ]
    }
   ],
   "source": [
    "# Dictionary 생성\n",
    "dictionary = Dictionary(texts_bigram)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
    "\n",
    "# Corpus 생성  \n",
    "corpus = [dictionary.doc2bow(text) for text in texts_bigram]\n",
    "\n",
    "# 최적 토픽 수 찾기 (Coherence Score 사용)\n",
    "coherence_scores = []\n",
    "models_dict = {}\n",
    "topic_range = range(8, 10)\n",
    "\n",
    "for num_topics in topic_range:\n",
    "    lda_model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary, \n",
    "        num_topics=num_topics,\n",
    "        random_state=42,\n",
    "        passes=30,\n",
    "        alpha='auto',        # 자동 조정\n",
    "        per_word_topics=True\n",
    "        \n",
    "    )\n",
    "    \n",
    "    coherence_model = CoherenceModel(\n",
    "        model=lda_model, \n",
    "        texts=texts_bigram, \n",
    "        dictionary=dictionary, \n",
    "        coherence='c_v'\n",
    "    )\n",
    "    \n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    coherence_scores.append(coherence_score)\n",
    "    models_dict[num_topics] = lda_model\n",
    "    print(f\"토픽 수 {num_topics}: Coherence = {coherence_score:.4f}\")\n",
    "\n",
    "# 상위 3개 후보 선정\n",
    "top_3_indices = np.argsort(coherence_scores)[-3:]\n",
    "top_3_topics = [topic_range[i] for i in top_3_indices]\n",
    "print(f\"\\nCoherence 상위 3개: {top_3_topics}\")\n",
    "\n",
    "\n",
    "# 각 후보의 실제 토픽 내용 확인\n",
    "for num_topics in top_3_topics:\n",
    "    print(f\"\\n=== {num_topics}개 토픽 결과 ===\")\n",
    "    model = models_dict[num_topics]\n",
    "    \n",
    "    for topic_id in range(num_topics):\n",
    "        terms = model.show_topic(topic_id, topn=8)\n",
    "        words = [term[0] for term in terms]\n",
    "        print(f\"토픽 {topic_id}: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55d191fd-2054-4bc0-8513-0e0393cf7cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 8개 토픽 결과 ===\n",
      "토픽 0: 부부(0.1298), 제3자가(0.0844), 불법행위(0.0526), 부정행위(0.0511), 책임(0.0484), 생활_침해(0.0454), 행위(0.0372), 타인(0.0365)\n",
      "토픽 1: 재산_분할(0.0883), 청구(0.0731), 이혼(0.0708), 양육비(0.0546), 의무(0.0534), 부부(0.0380), 지급(0.0378), 이루어지다(0.0345)\n",
      "토픽 2: 법적(0.1050), 부정행위(0.0966), 책임(0.0859), 배우자(0.0613), 제3자가(0.0552), 부부_일방(0.0308), 지게(0.0302), 손해배상(0.0241)\n",
      "토픽 3: 기준(0.0945), 부정행위(0.0918), 청구(0.0906), 위자료(0.0728), 손해배상(0.0569), 산정(0.0399), 결정(0.0365), 위자료_액수(0.0349)\n",
      "토픽 4: 혼인_관계(0.1025), 파탄(0.0848), 공동(0.0640), 의무(0.0410), 부부(0.0402), 생활(0.0373), 기준(0.0299), 유지(0.0246)\n",
      "토픽 5: 부정행위(0.1208), 책임(0.1058), 제3자가(0.0998), 손해배상(0.0870), 부부_일방(0.0712), 배우자(0.0522), 불법행위(0.0429), 재산_분할(0.0315)\n",
      "토픽 6: 손해배상(0.1359), 부정행위(0.1300), 청구(0.1235), 배우자(0.0790), 정신(0.0590), 정신_고통(0.0494), 손해(0.0473), 범위(0.0302)\n",
      "토픽 7: 부정_행위(0.0839), 범위(0.0565), 법률(0.0553), 이혼(0.0375), 민법(0.0346), 배우자(0.0324), 이혼소송(0.0307), 평(0.0297)\n",
      "\n",
      "=== 9개 토픽 결과 ===\n",
      "토픽 0: 부부(0.0798), 책임(0.0732), 제3자가(0.0684), 부정행위(0.0649), 손해배상(0.0548), 대해(0.0366), 불법행위(0.0360), 타인(0.0308)\n",
      "토픽 1: 이혼(0.1407), 재산_분할(0.0912), 청구(0.0547), 양육비(0.0509), 의무(0.0508), 지급(0.0429), 법적(0.0353), 이루어지다(0.0341)\n",
      "토픽 2: 법적(0.0866), 부정행위(0.0565), 책임(0.0563), 다른(0.0436), 부부(0.0363), 제3자는(0.0298), 파탄_초래(0.0261), 한쪽(0.0224)\n",
      "토픽 3: 기준(0.1754), 부정행위(0.0583), 위자료_액수(0.0576), 산정(0.0443), 결정(0.0421), 사실혼_관계(0.0296), 손해배상(0.0241), 청구(0.0238)\n",
      "토픽 4: 부부(0.1479), 혼인_관계(0.0810), 파탄(0.0654), 불법행위(0.0492), 제3자가(0.0479), 책임(0.0448), 행위(0.0440), 제3자의(0.0427)\n",
      "토픽 5: 부정행위(0.1482), 제3자가(0.1201), 책임(0.1119), 부부_일방(0.0775), 배우자(0.0756), 손해배상(0.0713), 법적(0.0371), 불법행위(0.0355)\n",
      "토픽 6: 청구(0.1621), 손해배상(0.1525), 부정행위(0.1363), 배우자(0.0835), 정신_고통(0.0569), 위자료(0.0543), 정신(0.0270), 결정(0.0177)\n",
      "토픽 7: 부정_행위(0.0865), 민법(0.0484), 규정(0.0481), 간통(0.0378), 권리(0.0378), 범위(0.0337), 제840조(0.0325), 배우자(0.0303)\n",
      "토픽 8: 범위(0.1086), 손해(0.1028), 정신(0.0636), 배상(0.0609), 법률(0.0498), 불법행위(0.0382), 청구(0.0375), 부정행위(0.0365)\n"
     ]
    }
   ],
   "source": [
    "for num_topics in top_3_topics:\n",
    "    print(f\"\\n=== {num_topics}개 토픽 결과 ===\")\n",
    "    model = models_dict[num_topics]\n",
    "    \n",
    "    for topic_id in range(num_topics):\n",
    "        terms = model.show_topic(topic_id, topn=8)\n",
    "        topic_str = ', '.join([f\"{word}({weight:.4f})\" for word, weight in terms])\n",
    "        print(f\"토픽 {topic_id}: {topic_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a76876-46ae-4059-8ba4-2cbfcad91277",
   "metadata": {},
   "source": [
    "# 4단계: 최종 토픽 라벨 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a659b7-8df8-4d89-b538-9b242be63f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 토픽 수: 9\n"
     ]
    }
   ],
   "source": [
    "# 8개 토픽 모델 선택\n",
    "optimal_num_topics = 9\n",
    "best_model = models_dict[optimal_num_topics]  # coherence 결과에서 9개 토픽 모델\n",
    "\n",
    "print(f\"선택된 토픽 수: {optimal_num_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "621a7fed-8bbb-4e07-803a-97a52d54d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2 = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d9d457a-0ad6-4172-9e0d-ba162f6ee648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문서가 어떤 토픽에 속하는지 결정하는 단계\n",
    "def assign_document_topics(model, corpus):\n",
    "    topic_assignments = []\n",
    "    topic_probabilities = []\n",
    "    \n",
    "    for doc_bow in corpus:\n",
    "        doc_topics = model.get_document_topics(doc_bow)\n",
    "        \n",
    "        if doc_topics:\n",
    "            # 가장 높은 확률의 토픽 찾기\n",
    "            dominant_topic = max(doc_topics, key=lambda x: x[1])\n",
    "            topic_assignments.append(dominant_topic[0])      # 토픽 번호\n",
    "            topic_probabilities.append(dominant_topic[1])    # 확률\n",
    "        else:\n",
    "            topic_assignments.append(-1)\n",
    "            topic_probabilities.append(0.0)\n",
    "    \n",
    "    return topic_assignments, topic_probabilities\n",
    "\n",
    "# 실행\n",
    "topic_ids, topic_probs = assign_document_topics(best_model, corpus)\n",
    "\n",
    "# DataFrame에 추가\n",
    "df_clean2['topic_label'] = topic_ids\n",
    "df_clean2['topic_probability'] = topic_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "829bc994-f294-48a8-8983-ceb12ea799a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_labels = {\n",
    "    0: \"제3자 개입과 공동 불법행위 책임\",      \n",
    "    1: \"이혼 시 금전 문제 (재산분할 및 양육비)\",     \n",
    "    2: \"혼인 파탄의 원인과 법적 책임\",       \n",
    "    3: \"위자료 액수 산정 기준 및 결정 요소\",   \n",
    "    4: \"제3자 개입으로 인한 혼인 관계 파탄\",     \n",
    "    5: \"유책배우자_제3자의 연대 책임_손해배상\",     \n",
    "    6: \"정신적 고통에 대한 위자료 청구_액수\",    \n",
    "    7: \"부정행위의 법률적 근거 (민법 제840조)\",\n",
    "    8: \"손해배상의 법적 인정 범위\"\n",
    "    \n",
    "}\n",
    "\n",
    "# DataFrame에 토픽 이름 추가\n",
    "df_clean2['topic_name'] = df_clean2['topic_label'].map(topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "debc5b9d-6c65-4f0a-8d73-c7fca4707b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 토픽 0 대표 문서 ===\n",
      "1. (확률: 0.940)\n",
      "   제3자가 부부 관계에 개입하여 혼인 생활을 방해한 경우 이는 불법 행위로 간주될 수 있는 조건은 무엇인가요?...\n",
      "2. (확률: 0.940)\n",
      "   부부공동생활을 방해하는 부정행위에 대해 제3자가 불법행위로 인한 손해배상 책임을 지는 경우는 무엇인가요?...\n",
      "\n",
      "=== 토픽 1 대표 문서 ===\n",
      "1. (확률: 0.941)\n",
      "   양육비를 합의서에서 재산 이전이나 금전 지급으로 약정하는 경우 어떻게 해석되나요?...\n",
      "2. (확률: 0.926)\n",
      "   약정금 지급의무와 관련된 분쟁에서 양육비 채권과의 상계가 인정될 수 있는 조건은 무엇인가요?...\n",
      "\n",
      "=== 토픽 2 대표 문서 ===\n",
      "1. (확률: 0.924)\n",
      "   부동산 매각대금의 지급과 관련하여 상속인들 간의 분쟁이 있을 때, 이를 해결하는 기본적인 법적 절차는 무엇인가요?...\n",
      "2. (확률: 0.924)\n",
      "   다른 사람과 부정행위를 하여 부부공동생활을 침해한 제3자는 어떤 법적 책임이 있나요?...\n",
      "\n",
      "=== 토픽 3 대표 문서 ===\n",
      "1. (확률: 0.964)\n",
      "   '혼인관계 해소에 따른 재산분할이 확정되었음을 전제로 채무의 존부 확인 및 불이행을 이유로 한 손해배상 청구'의 소송이 계속 중인 경우 본소 청구와 반소 청구의 이유는 어떻게 되나...\n",
      "2. (확률: 0.948)\n",
      "   부부의 단독 명의로 취득한 부동산의 소유권 판단에서 특유재산의 추정은 어떻게 이루어지며, 이를 번복하기 위한 증명책임은 누구에게 있나요?...\n",
      "\n",
      "=== 토픽 4 대표 문서 ===\n",
      "1. (확률: 0.950)\n",
      "   부부가 장기간 별거하여 부부공동생활이 파탄된 경우 제3자가 부부 일방과 성적인 행위를 할 때 법률적으로 어떻게 평가하나요?...\n",
      "2. (확률: 0.939)\n",
      "   제3자가 부부 관계에 개입하여 법적인 문제가 되는 행위를 했을 때, 어떤 사유로 불법행위가 성립하나요?...\n",
      "\n",
      "=== 토픽 5 대표 문서 ===\n",
      "1. (확률: 0.949)\n",
      "   제3자가 부부의 일방과 부정행위를 하여 혼인의 본질에 해당하는 부부공동생활을 침해한 경우, 그로 인한 손해배상 책임은 어떻게 발생하나요?...\n",
      "2. (확률: 0.949)\n",
      "   제3자가 부부의 일방과 부정행위를 함으로써 배우자에게 정신적 고통을 가할 경우 법적으로 어떤 책임을 져야 하나요?...\n",
      "\n",
      "=== 토픽 6 대표 문서 ===\n",
      "1. (확률: 0.948)\n",
      "   부부 일방의 부정행위로 인해 상대 배우자가 정신적 고통을 입었을 때, 위자료의 금액은 어떻게 결정되나요?...\n",
      "2. (확률: 0.942)\n",
      "   배우자의 부정행위로 인한 정신적 손해배상 청구에서 법원의 고려사항은 무엇인가요?...\n",
      "\n",
      "=== 토픽 7 대표 문서 ===\n",
      "1. (확률: 0.922)\n",
      "   혼인 중인 사실을 속이고 결혼을 전제로 교제한 경우, 성적 자기결정권 침해가 성립하는 조건은 무엇인가요?...\n",
      "2. (확률: 0.922)\n",
      "   민법 제840조 제1호에서 규정하는 배우자의 부정한 행위의 범위는 무엇인가요?...\n",
      "\n",
      "=== 토픽 8 대표 문서 ===\n",
      "1. (확률: 0.940)\n",
      "   미성년자가 불법행위로 인해 손해를 발생시킨 경우, 그 감독의무자의 책임 인정 범위는 어떻게 결정되나요?...\n",
      "2. (확률: 0.933)\n",
      "   부부 간 임대차계약에서 임대차보증금 반환채권의 소유 여부를 입증하기 위한 조건은 무엇인가요?...\n",
      "토픽 확률 통계:\n",
      "count    709.000000\n",
      "mean       0.707344\n",
      "std        0.177552\n",
      "min        0.311532\n",
      "25%        0.541480\n",
      "50%        0.700992\n",
      "75%        0.894649\n",
      "max        0.964439\n",
      "Name: topic_probability, dtype: float64\n",
      "애매한 할당: 0개 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# 1. 토픽별 대표 문서 확인\n",
    "def show_topic_examples(df, topic_label, n_examples=3):\n",
    "    topic_docs = df[df['topic_label'] == topic_id].sort_values('topic_probability', ascending=False)\n",
    "    \n",
    "    print(f\"\\n=== 토픽 {topic_id} 대표 문서 ===\")\n",
    "    for i, (idx, row) in enumerate(topic_docs.head(n_examples).iterrows()):\n",
    "        print(f\"{i+1}. (확률: {row['topic_probability']:.3f})\")\n",
    "        print(f\"   {row['input'][:100]}...\")\n",
    "\n",
    "# 모든 토픽 확인\n",
    "for topic_id in range(9):\n",
    "    show_topic_examples(df_clean2, topic_id, n_examples=2)\n",
    "\n",
    "# 2. 확률 분포 확인\n",
    "print(\"토픽 확률 통계:\")\n",
    "print(df_clean2['topic_probability'].describe())\n",
    "\n",
    "# 3. 애매한 할당 확인 (확률 < 0.3)\n",
    "low_confidence = df_clean2[df_clean2['topic_probability'] < 0.3]\n",
    "print(f\"애매한 할당: {len(low_confidence)}개 ({len(low_confidence)/len(df_clean2)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb298370-e004-43ba-a60d-b1bac09b7295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "애매한 할당 문서들:\n"
     ]
    }
   ],
   "source": [
    "# 이 2개는 어떤 문서인지 확인해보면 좋을 것 같아요\n",
    "low_confidence = df_clean2[df_clean2['topic_probability'] < 0.3]\n",
    "print(\"애매한 할당 문서들:\")\n",
    "for idx, row in low_confidence.iterrows():\n",
    "    print(f\"- {row['input'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd7a6480-6649-4c67-bd36-ffd8421e5610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 전체 토픽 이름 목록 ===\n",
      "정신적 고통에 대한 위자료 청구_액수: 197개\n",
      "유책배우자_제3자의 연대 책임_손해배상: 147개\n",
      "이혼 시 금전 문제 (재산분할 및 양육비): 91개\n",
      "위자료 액수 산정 기준 및 결정 요소: 75개\n",
      "손해배상의 법적 인정 범위: 55개\n",
      "제3자 개입과 공동 불법행위 책임: 50개\n",
      "제3자 개입으로 인한 혼인 관계 파탄: 44개\n",
      "혼인 파탄의 원인과 법적 책임: 30개\n",
      "부정행위의 법률적 근거 (민법 제840조): 20개\n"
     ]
    }
   ],
   "source": [
    "# 모든 토픽 이름 출력해서 확인\n",
    "print(\"=== 전체 토픽 이름 목록 ===\")\n",
    "all_topics = df_clean2['topic_name'].value_counts()\n",
    "for topic_name, count in all_topics.items():\n",
    "    print(f\"{topic_name}: {count}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8b808a8-7a31-4e00-8327-fae4b7fd6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 카테고리별 포함 토픽 이름 리스트\n",
    "category_map = {\n",
    "    \"위자료_관련\": [\n",
    "        \"정신적 고통에 대한 위자료 청구_액수\",\n",
    "        \"위자료 액수 산정 기준 및 결정 요소\",\n",
    "        \"손해배상의 법적 인정 범위\",\n",
    "        \"유책배우자_제3자의 연대 책임_손해배상\",\n",
    "        \"이혼 시 금전 문제 (재산분할 및 양육비)\"\n",
    "    ],\n",
    "    \"불법행위_책임\": [\"제3자 개입과 공동 불법행위 책임\",\n",
    "                    \"제3자 개입으로 인한 혼인 관계 파탄\",\n",
    "                   \"혼인 파탄의 원인과 법적 책임\",\n",
    "                   \"부정행위의 법률적 근거 (민법 제840조)\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e3b45e0-e55c-4188-84f5-9828cd3026eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_name → 상위 카테고리 매핑 함수\n",
    "def map_to_category(topic_name):\n",
    "    for category, names in category_map.items():\n",
    "        if topic_name in names:\n",
    "            return category\n",
    "    return \"기타\"\n",
    "\n",
    "# 새로운 컬럼 생성\n",
    "df_clean2['super_category'] = df_clean2['topic_name'].apply(map_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ded7f82d-f5a0-4449-acbc-2cadffe2e37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폭넓은 위자료 관련 사건: 565개\n",
      "topic_name\n",
      "정신적 고통에 대한 위자료 청구_액수       197\n",
      "유책배우자_제3자의 연대 책임_손해배상      147\n",
      "이혼 시 금전 문제 (재산분할 및 양육비)     91\n",
      "위자료 액수 산정 기준 및 결정 요소        75\n",
      "손해배상의 법적 인정 범위              55\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 위자료_관련 문서 수\n",
    "alimony_broad = df_clean2[df_clean2['super_category'] == \"위자료_관련\"]\n",
    "print(f\"폭넓은 위자료 관련 사건: {len(alimony_broad)}개\")\n",
    "\n",
    "# 토픽별 건수\n",
    "print(alimony_broad['topic_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65ecf17a-cc54-465d-83c1-78c8a8d2d190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 결과 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "# 최종 결과 저장\n",
    "final_columns = ['input', 'output', 'input_processed', 'is_divorce', 'topic_label',  'super_category', 'topic_name', 'topic_probability', 'announce_date']\n",
    "\n",
    "final_df = df_clean2[final_columns].copy()\n",
    "final_df.to_csv(\"C:/Users/82105/Downloads/divorce_topic_labeled_input.csv\", index=False, encoding='utf-8-sig')\n",
    "print(\"최종 결과 저장 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
