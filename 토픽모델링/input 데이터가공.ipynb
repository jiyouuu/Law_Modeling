{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e55b1e1-3333-4767-b8dd-740574ebd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a4a5c1-8c57-4d65-9350-0862669910ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Index(['score', 'confidence', 'classification', 'tier1_count', 'tier2_count',\n",
      "       'tier3_count', 'keyword_density', 'text_length', 'reason', 'doc_id',\n",
      "       'casetype', 'casenames', 'input', 'output', 'title', 'fileName',\n",
      "       'announce_date', 'decision_date', 'response_date', 'row_index',\n",
      "       'is_divorce'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_not = pd.read_csv(\"C:/Users/82105/Downloads/divorce_not_related_true.csv\", encoding=\"utf-8-sig\") # 이혼 아님\n",
    "df = pd.read_csv(\"C:/Users/82105/Downloads/merged_score.csv\", encoding=\"utf-8-sig\")   #이혼 \n",
    "\n",
    "df['is_divorce'] = 1\n",
    "df_not['is_divorce'] = 0\n",
    "\n",
    "# 두 데이터프레임 합치기\n",
    "combined_df = pd.concat([df, df_not], ignore_index=True)\n",
    "\n",
    "cols = combined_df.columns\n",
    "print(len(cols))   # 컬럼 개수 확인\n",
    "print(cols)  \n",
    "\n",
    "combined_df.to_csv(\"C:/Users/82105/Downloads/combined2.csv\", index=False, encoding='utf-8-sig')\n",
    "combined_df = pd.read_csv(\"C:/Users/82105/Downloads/combined.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# 전처리를 적용할 컬럼을 확인합니다. 'input'과 'output' 컬럼이 중요해 보입니다.\n",
    "# 혹시 데이터가 없는 경우(NaN)를 대비해 빈 문자열로 채워줍니다.\n",
    "combined_df['input'] = combined_df['input'].fillna('')\n",
    "combined_df['output'] = combined_df['output'].fillna('')\n",
    "\n",
    "# 모델 3 : 답변 검색 모델을 위한 '통합' 텍스트 컬럼 생성\n",
    "combined_df['text_combined'] = combined_df['input'].astype(str) + \" \" + combined_df['output'].astype(str)\n",
    "\n",
    "print(\"전처리 전 데이터 샘플:\")\n",
    "print(combined_df[['input', 'output']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "64876aa3-6673-4290-9bf7-04c07798bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv(\"C:/Users/82105/Downloads/combined_before_jeon.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56272af6-c515-496a-80e9-43ed43d497f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df2.to_csv(\"C:/Users/82105/Downloads/combined_before_jeon.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f6d196ec-db38-4418-839c-f6e403f63fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 이혼 관련 문서만 토픽 모델링 시작 ===\n",
      "📊 데이터 분할:\n",
      "  • 이혼 관련 문서: 741개\n",
      "  • 비이혼 관련 문서: 3706개\n",
      "  • 전체: 4447개\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 이혼 관련 문서만 토픽 모델링 시작 ===\")\n",
    "divorce_df = combined_df[combined_df['is_divorce'] == 1].copy()\n",
    "non_divorce_df = combined_df[combined_df['is_divorce'] == 0].copy()\n",
    "\n",
    "print(f\"📊 데이터 분할:\")\n",
    "print(f\"  • 이혼 관련 문서: {len(divorce_df)}개\")\n",
    "print(f\"  • 비이혼 관련 문서: {len(non_divorce_df)}개\")\n",
    "print(f\"  • 전체: {len(combined_df)}개\")\n",
    "\n",
    "# 이혼 문서만으로 토픽 모델링\n",
    "divorce_df['topic_label'] = -1  # 빈 컬럼 생성\n",
    "\n",
    " # 비이혼 문서는 topic_label = -1 유지\n",
    "non_divorce_df['topic_label'] = -1  # 미분류로 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68d7e304-b176-49e7-8322-93b5a237d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "divorce_df.to_csv(\"C:/Users/82105/Downloads/divorce_df.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835b90b4-f637-4e36-85e5-403904366883",
   "metadata": {},
   "source": [
    "# 1단계 : KoNLPy를 사용한 정교한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2827432b-b903-46b0-bbbb-4c6d4526317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMAL_STOPWORDS = [\n",
    "    '것', '수', '때', '등', '들', '더', '이', '그', '저', '나', \n",
    "    '우리', '같', '또', '만', '년', '월', '일', '하다', '있다', '되다',\n",
    "\n",
    "     '가능하다', '가능', '가다', '되다', '하다', '있다', '없다', '않다', '된다', '한다',\n",
    "    '어떻게', '어떤', '무엇', '언제', '어디서', '왜', '누가', '얼마', '몇',\n",
    "    '알고', '싶다', '궁금하다', '문의', '질문', '답변', '설명', '이해',\n",
    "    '과정', '절차', '이후', '다음', '먼저', '그리고', '그러나', '하지만', '그래서', '제자','제호',\n",
    "\n",
    "     '없', '있', '하', '되', '않',  '행위',\n",
    "    '나', '우리', '너', '당신', '같', '또', '것', '때', '등', \n",
    "    '때문', '정도', '사실', '생각', '경우', '문제', '방법', '상황', '내용', '결과', '사람',\n",
    "\n",
    "    '해야', '하면', '경우', '때는', '어느', '무슨', '어디', '누구' , ' 가지다' , '가지''하나요', '위해', '이혼'\n",
    "]\n",
    "\n",
    "# # 법률 전문용어는 무조건 포함\n",
    "# LEGAL_KEYWORDS = [ '위자료', '재산분할', '양육권', '친권', '면접교섭', \n",
    "#     '협의이혼', '청구', '배상', '손해', '책임',\n",
    "#     '차용금', '반환', '취소', '원상회복', '사해행위', '채권자', '배우자', '이혼사유',\n",
    "#      '이혼', '사유', \n",
    "#     '혼인', '금전거래', '청구권',  '액수', '정해지', '부적법',\n",
    "#     '혼인파탄', '파탄', '분할', '양육비', '면접',\n",
    "#     '교섭', '협의', '조정신청', '손해배상', '부부', '배우자', '당사자', '사람', '개인', '상대방'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "015f1680-4583-4570-b406-966a8e6ec2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):  # 전처리 함수 \n",
    "    \"\"\"\n",
    "    한국어 텍스트를 입력받아 전처리하는 함수:\n",
    "    1. '제3자' 형태의 단어를 임시 토큰으로 보호/복원하여 숫자를 보존.\n",
    "    2. 불필요한 한글 이외의 문자를 제거.\n",
    "    3. 형태소 분석 및 어간 추출.\n",
    "    4. 불용어 및 1글자 단어 제거.\n",
    "    \"\"\"\n",
    "    # 1단계: 한글, 공백을 제외한 모든 문자 제거\n",
    "    # re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', text)는 한글과 공백만 남기고 나머지는 지우라는 의미\n",
    "    # 제숫자 + 한글 글자 + 선택적 조사까지 포함\n",
    "    # 딕셔너리를 함수 내부에 선언하여 매 호출마다 초기화 (핵심 수정 사항)\n",
    "    protected_matches = {}\n",
    "\n",
    "    def protect_term(match):\n",
    "        # 찾은 문자열(예: '제3자')을 고유한 토큰(예: '###TOKEN0###')으로 매핑\n",
    "        token = f\"###TOKEN{len(protected_matches)}###\"\n",
    "        protected_matches[token] = match.group(0)\n",
    "        return match.group(0) # 일단 원본 단어 그대로 둔 채로 형태소 분석 진행\n",
    "    def strip_josa(text):\n",
    "    # 한글 명사 뒤 “의”, “가”, “을” 등 제거\n",
    "        return re.sub(r'([가-힣]+)(의|가|를|은|는|과|와)$', r'\\1', text)\n",
    "    \n",
    "\n",
    "    # 1단계: '제3자' 형태의 단어를 임시 토큰으로 치환하여 보호\n",
    "    re.sub(r'(제\\d+[가-힣]+)', protect_term, text)\n",
    "\n",
    "    # 2단계: 한글, 공백, 보호 토큰의 문자(#)만 남기고 제거\n",
    "    text = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣# ]', '', text)\n",
    "\n",
    "    # 2단계: Okt 형태소 분석기를 이용한 토큰화 및 어간 추출(Stemming)\n",
    "    # okt.pos(text, stem=True)는 문장을 (단어, 품사) 형태로 나누고, '하다', '먹다'처럼 원형으로 만들어줍니다.\n",
    "    # 예: \"먹었었고\" -> ('먹다', 'Verb')\n",
    "    # Okt 형태소 분석기 객체 생성\n",
    "    okt = Okt()\n",
    "    word_tokens = okt.pos(text, stem=True)\n",
    "\n",
    "    # 3단계: 불용어 제거\n",
    "    # 형태소 분석 후 의미 있는 단어만 추출하는 필터링 과정\n",
    "    # 의미를 가지는 명사, 동사, 형용사, 부사 중에서 1글자 이상인 단어만 추출합니다.\n",
    "    # 품사 태그가 'Josa'(조사), 'Eomi'(어미), 'Punctuation'(구두점) 등인 단어들을 제거합니다.\n",
    "    meaningful_words = []\n",
    "    for word, pos in word_tokens:\n",
    "        if word in LEGAL_KEYWORDS:\n",
    "            meaningful_words.append(word)\n",
    "        elif pos in ['Noun',' Verb'] and len(word) > 1:\n",
    "            token = strip_josa(word)\n",
    "            if token not in MINIMAL_STOPWORDS:\n",
    "                meaningful_words.append(token)\n",
    "     # 6. 보호된 단어 강제 포함 및 복원 (핵심)\n",
    "    # 보호 목록에 있던 단어들을 강제로 최종 리스트에 추가합니다.\n",
    "    # (이미 리스트에 분해되어 들어갔을 수 있지만, 완벽한 복원을 위해 강제 추가)\n",
    "    for original_term in protected_matches.values():\n",
    "        # '제3자' 자체를 하나의 단어로 명시적으로 추가\n",
    "        meaningful_words.append(original_term)\n",
    "        \n",
    "    # 7. 중복 제거 및 최종 문자열 반환\n",
    "    # Set을 이용해 중복 제거 후 리스트로 변환\n",
    "    final_words = list(set(meaningful_words))\n",
    "    # 최종적으로 공백으로 연결된 문자열을 반환합니다. \n",
    "    # 모델에 따라 리스트 형태(meaningful_words)를 그대로 사용할 수도 있습니다.\n",
    "    # 텍스트에서 분석에 의미 있는 핵심 단어들만 남긴 리스트 생성\n",
    "    return ' '.join(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f61de42c-ea4f-44e3-b8c9-1ec0bf78e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 각 목적에 맞게 전처리 컬럼 생성 ---\n",
    "# 질문 의도 파악 모델용: 'input' 컬럼만 전처리\n",
    "# 'input' 컬럼에 전처리 함수를 적용하여 새로운 'input_processed' 컬럼 생성\n",
    "divorce_df['input_processed'] = divorce_df['input'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "50100ade-6ada-464c-a3f3-974e25400dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "divorce_df['combined_processed'] = divorce_df['text_combined'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "45be4962-433a-4e72-9404-b95ec105d298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 전처리 전/후 비교 ===\n",
      "원본 [0]: 혼인 중 발생한 금전거래와 관련하여 차용금 반환 청구권이 인정되는 조건은 무엇인가요?\n",
      "결과 [0]: 거래 차용 발생 청구권 관련 인정 조건 금전 혼인 반환\n",
      "\n",
      "원본 [1]: 제3자가 부부의 일방과 부정행위를 할 경우 어떤 법적 책임을 지게 되나요?\n",
      "결과 [1]: 부부 부정행위 책임 일방 법적 지게 제3자가\n",
      "\n",
      "원본 [2]: 민법 제840조 제1호에서 규정한 재판상 이혼사유 중 부정한 행위의 의미는 무엇인가요?\n",
      "결과 [2]: 규정 제조 사유 이혼 제840조 민법 부정 제1호에서 의미 재판\n",
      "\n",
      "원본 [3]: 배우자가 있는 사람과 부정행위를 한 경우 위자료의 액수는 어떻게 정해지나요?\n",
      "결과 [3]: 배우자 액수 부정행위 위자료\n",
      "\n",
      "원본 [4]: 사해행위 취소 및 원상회복청구 소송에서 다른 채권자의 청구가 부적법해지는 상황은 어떤 경우인가요?\n",
      "결과 [4]: 법해 소송 원상회복 부적 청구 채권자 취소 사해행위 다른\n",
      "\n",
      "=== 각 목적에 맞게 생성된 전처리 컬럼들 ===\n",
      "                                               input  \\\n",
      "0    혼인 중 발생한 금전거래와 관련하여 차용금 반환 청구권이 인정되는 조건은 무엇인가요?   \n",
      "1          제3자가 부부의 일방과 부정행위를 할 경우 어떤 법적 책임을 지게 되나요?   \n",
      "2   민법 제840조 제1호에서 규정한 재판상 이혼사유 중 부정한 행위의 의미는 무엇인가요?   \n",
      "3         배우자가 있는 사람과 부정행위를 한 경우 위자료의 액수는 어떻게 정해지나요?   \n",
      "4  사해행위 취소 및 원상회복청구 소송에서 다른 채권자의 청구가 부적법해지는 상황은 어...   \n",
      "\n",
      "                       input_processed  \n",
      "0       거래 차용 발생 청구권 관련 인정 조건 금전 혼인 반환  \n",
      "1             부부 부정행위 책임 일방 법적 지게 제3자가  \n",
      "2  규정 제조 사유 이혼 제840조 민법 부정 제1호에서 의미 재판  \n",
      "3                      배우자 액수 부정행위 위자료  \n",
      "4      법해 소송 원상회복 부적 청구 채권자 취소 사해행위 다른  \n"
     ]
    }
   ],
   "source": [
    "# 결과 비교를 위해 원본과 처리된 결과를 나란히 출력\n",
    "print(\"\\n=== 전처리 전/후 비교 ===\")\n",
    "for i in range(5):\n",
    "    print(f\"원본 [{i}]: {divorce_df['input'].iloc[i]}\")\n",
    "    print(f\"결과 [{i}]: {divorce_df['input_processed'].iloc[i]}\\n\")\n",
    "\n",
    "\n",
    "# 전처리된 데이터가 포함된 데이터프레임 확인\n",
    "print(\"=== 각 목적에 맞게 생성된 전처리 컬럼들 ===\")\n",
    "print(divorce_df[['input', 'input_processed']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da24447-9fd0-4bed-a327-5110a899ca65",
   "metadata": {},
   "source": [
    "# 2단계: 최적화된 TF-IDF 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "63d24389-f586-4001-9a80-bead82885b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 행렬 크기: (741, 287)\n",
      "문서 수: 741\n",
      "특성(단어) 수: 287\n",
      "상위 10개 특성: ['간주' '간통' '개입' '개입 생활' '결정' '결정 손해배상' '결정 요소' '결정 정신' '계약' '고려']\n",
      "상위 20개 특성: ['간주' '간통' '개입' '개입 생활' '결정' '결정 손해배상' '결정 요소' '결정 정신' '계약' '고려' '고려 법원'\n",
      " '고려 청구' '고통' '고통 손해배상' '고통 정신' '고통 청구' '공동' '관계' '관계 대한' '관계 부정행위']\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터를 머신러닝 알고리즘이 처리할 수 있는 수치 벡터로 변환\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TF-IDF Vectorizer 설정\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,      # 상위 빈도 1000개 단어만 사용\n",
    "    min_df=5,\n",
    "    max_df=0.5,           # 80% 이상 문서에 나타나는 단어 제거\n",
    "    lowercase=False,         # 소문자 변환 x\n",
    "    ngram_range=(1, 2),     # 1-gram, 2-gram 모두 사용\n",
    "    sublinear_tf=True,            # TF 값에 로그 스케일 적용 (성능 향상)\n",
    "    token_pattern=r'[가-힣]{2,}', # 한글 2글자 이상\n",
    ")\n",
    "\n",
    "# TF-IDF 행렬 생성\n",
    "tfidf_matrix = vectorizer.fit_transform(divorce_df['input_processed'])  # X는 (문서 수 × 단어 수) 크기의 희소 행렬\n",
    "\n",
    "print(f\"TF-IDF 행렬 크기: {tfidf_matrix.shape}\")\n",
    "print(f\"문서 수: {tfidf_matrix.shape[0]}\")\n",
    "print(f\"특성(단어) 수: {tfidf_matrix.shape[1]}\")\n",
    "\n",
    "# 특성 이름(단어들) 확인\n",
    "# vectorizer.get_feature_names_out()로 어떤 단어가 벡터에 들어갔는지 확인 가능\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"상위 10개 특성: {feature_names[:10]}\")\n",
    "print(f\"상위 20개 특성: {feature_names[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f42c30-d2ed-44f0-9729-57c401649768",
   "metadata": {},
   "source": [
    "# 3단계: 토픽 개수 최적화\n",
    "# 최적의 토픽 개수를 찾기 위해 여러 지표를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b565c218-e853-4461-8257-dd99312a61fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토픽 수 2: Perplexity = 35462.0094\n",
      "토픽 수 3: Perplexity = 43615.2530\n",
      "토픽 수 4: Perplexity = 60242.6583\n",
      "토픽 수 5: Perplexity = 57516.5650\n",
      "토픽 수 6: Perplexity = 63302.6877\n",
      "토픽 수 7: Perplexity = 78152.4240\n",
      "토픽 수 8: Perplexity = 80238.3525\n",
      "토픽 수 9: Perplexity = 95862.0042\n",
      "토픽 수 10: Perplexity = 84849.3090\n",
      "최적의 토픽 수 (Perplexity 기준): 2\n"
     ]
    }
   ],
   "source": [
    "# 4-1. LDA Perplexity 계산 (낮을수록 좋음)\n",
    "\n",
    "# 토픽 개수별 Perplexity 계산\n",
    "perplexity_scores = []\n",
    "topic_range = range(2, 11)  # 2~10개 토픽 테스트\n",
    "\n",
    "for n_topics in topic_range:\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=n_topics, \n",
    "        random_state=42,\n",
    "        max_iter=100,\n",
    "        doc_topic_prior=0.1,      # 문서-토픽 분포 조정\n",
    "        topic_word_prior=0.01     # 토픽-단어 분포 조정\n",
    "    )\n",
    "    lda.fit(tfidf_matrix)\n",
    "    perplexity = lda.perplexity(tfidf_matrix)\n",
    "    perplexity_scores.append(perplexity)\n",
    "    print(f\"토픽 수 {n_topics}: Perplexity = {perplexity:.4f}\")\n",
    "\n",
    "# 최적의 토픽 수 선택\n",
    "optimal_topics = topic_range[np.argmin(perplexity_scores)]\n",
    "print(f\"최적의 토픽 수 (Perplexity 기준): {optimal_topics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51264159-071b-448a-b0cf-594b49990709",
   "metadata": {},
   "source": [
    "# 더 정확한 토픽 모델링을 위해 Gensim 라이브러리를 사용\n",
    "# 고급 기법: Gensim LDA + Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "42001eee-6a3a-4fc4-aab4-fee5f56be87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토픽 수 2: Coherence = 0.3097\n",
      "토픽 수 3: Coherence = 0.3209\n",
      "토픽 수 4: Coherence = 0.3330\n",
      "토픽 수 5: Coherence = 0.3446\n",
      "토픽 수 6: Coherence = 0.3491\n",
      "토픽 수 7: Coherence = 0.3603\n",
      "토픽 수 8: Coherence = 0.3724\n",
      "토픽 수 9: Coherence = 0.3339\n",
      "토픽 수 10: Coherence = 0.3382\n",
      "토픽 수 11: Coherence = 0.3442\n",
      "\n",
      "Coherence 상위 3개: [6, 7, 8]\n",
      "\n",
      "=== 6개 토픽 결과 ===\n",
      "토픽 0: 손해, 정신, 배상, 입증, 부정행위, 적용, 청구, 대한\n",
      "토픽 1: 부부, 생활, 제3자가, 책임, 조건, 혼인, 침해, 법적\n",
      "토픽 2: 청구, 위자료, 부정행위, 손해배상, 대한, 기준, 범위, 인정\n",
      "토픽 3: 재산, 분할, 이혼, 청구, 고려, 요소, 양육비, 판단\n",
      "토픽 4: 부정행위, 손해배상, 배우자, 책임, 제3자가, 조건, 부부, 일방\n",
      "토픽 5: 관계, 혼인, 인정, 부정, 사실혼, 배우자, 파탄, 조건\n",
      "\n",
      "=== 7개 토픽 결과 ===\n",
      "토픽 0: 정신, 손해배상, 부정행위, 고통, 청구, 손해, 배상, 배우자\n",
      "토픽 1: 재산, 분할, 이혼, 조건, 부부, 사해행위, 효력, 추정\n",
      "토픽 2: 청구, 위자료, 부정행위, 손해배상, 범위, 기준, 결정, 대한\n",
      "토픽 3: 요소, 고려, 청구, 양육비, 판단, 법원, 대한, 기준\n",
      "토픽 4: 부정행위, 배우자, 손해배상, 조건, 책임, 청구, 법적, 부부\n",
      "토픽 5: 관계, 혼인, 부정, 배우자, 사실혼, 인정, 파탄, 불법행위\n",
      "토픽 6: 부부, 제3자가, 부정행위, 책임, 생활, 불법행위, 조건, 일방\n",
      "\n",
      "=== 8개 토픽 결과 ===\n",
      "토픽 0: 손해, 배상, 정신, 발생, 대한, 고통, 관계, 해소\n",
      "토픽 1: 재산, 분할, 이혼, 조건, 효력, 사해행위, 부부, 인정\n",
      "토픽 2: 청구, 손해배상, 부정행위, 위자료, 범위, 결정, 기준, 소송\n",
      "토픽 3: 고려, 요소, 청구, 양육비, 기준, 판단, 법원, 위자료\n",
      "토픽 4: 부정행위, 배우자, 손해배상, 정신, 책임, 조건, 고통, 청구\n",
      "토픽 5: 관계, 혼인, 부정, 배우자, 사실혼, 인정, 파탄, 조건\n",
      "토픽 6: 부부, 책임, 제3자가, 부정행위, 조건, 생활, 손해배상, 법적\n",
      "토픽 7: 부부, 부정행위, 침해, 생활, 불법행위, 제3자가, 인정, 혼인\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# 텍스트를 토큰 리스트로 변환\n",
    "texts = [text.split() for text in divorce_df['input_processed']]\n",
    "\n",
    "# Dictionary 생성\n",
    "dictionary = Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
    "\n",
    "# Corpus 생성  \n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# 최적 토픽 수 찾기 (Coherence Score 사용)\n",
    "coherence_scores = []\n",
    "models_dict = {}\n",
    "topic_range = range(2, 12)\n",
    "\n",
    "for num_topics in topic_range:\n",
    "    lda_model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary, \n",
    "        num_topics=num_topics,\n",
    "        random_state=42,\n",
    "        passes=20,\n",
    "        alpha='auto',        # 자동 조정\n",
    "        per_word_topics=True\n",
    "        \n",
    "    )\n",
    "    \n",
    "    coherence_model = CoherenceModel(\n",
    "        model=lda_model, \n",
    "        texts=texts, \n",
    "        dictionary=dictionary, \n",
    "        coherence='c_v'\n",
    "    )\n",
    "    \n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    coherence_scores.append(coherence_score)\n",
    "    models_dict[num_topics] = lda_model\n",
    "    print(f\"토픽 수 {num_topics}: Coherence = {coherence_score:.4f}\")\n",
    "\n",
    "# 상위 3개 후보 선정\n",
    "top_3_indices = np.argsort(coherence_scores)[-3:]\n",
    "top_3_topics = [topic_range[i] for i in top_3_indices]\n",
    "print(f\"\\nCoherence 상위 3개: {top_3_topics}\")\n",
    "\n",
    "\n",
    "# 각 후보의 실제 토픽 내용 확인\n",
    "for num_topics in top_3_topics:\n",
    "    print(f\"\\n=== {num_topics}개 토픽 결과 ===\")\n",
    "    model = models_dict[num_topics]\n",
    "    \n",
    "    for topic_id in range(num_topics):\n",
    "        terms = model.show_topic(topic_id, topn=8)\n",
    "        words = [term[0] for term in terms]\n",
    "        print(f\"토픽 {topic_id}: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ce1ca-30ad-48e3-886f-131b3b63ffe5",
   "metadata": {},
   "source": [
    "# 4단계: LDA 토픽 모델링 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2d6e19a8-38d9-4b66-8c59-1329f7d735d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA 결과 형태: (741, 5)\n"
     ]
    }
   ],
   "source": [
    "# 최적의 토픽 수로 LDA 모델 생성 \n",
    "final_lda = LatentDirichletAllocation(\n",
    "    n_components=5,    # 최적 토픽 수 사용\n",
    "    random_state=42,\n",
    "    max_iter=100,\n",
    "    learning_method='batch',         # 또는 'online'\n",
    "    doc_topic_prior=0.1,        # 문서-토픽 분포 조정\n",
    "    topic_word_prior=0.01     # 토픽-단어 분포 조정\n",
    ")\n",
    "\n",
    "# LDA 모델 훈련 및 토픽 확률 계산\n",
    "lda_result = final_lda.fit_transform(tfidf_matrix)\n",
    "\n",
    "# 각 문서의 주요 토픽 결정 (확률이 가장 높은 토픽)\n",
    "topic_assignments = np.argmax(lda_result, axis=1)\n",
    "\n",
    "print(f\"LDA 결과 형태: {lda_result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84345c-6335-4003-aa2e-69677b53f8b4",
   "metadata": {},
   "source": [
    "# 5단계: 토픽별 주요 단어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f60c1753-e0f6-456b-8c7a-88e12d2926d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 토픽별 주요 단어 ===\n",
      "\n",
      "토픽 0:\n",
      "  이혼: 17.2834\n",
      "  재산: 11.8825\n",
      "  의무: 11.4772\n",
      "  분할: 10.9563\n",
      "  조건: 9.3630\n",
      "  요소: 8.4846\n",
      "  양육비: 7.9223\n",
      "  청구: 7.8003\n",
      "  지급: 7.5813\n",
      "  소송: 6.8999\n",
      "\n",
      "토픽 1:\n",
      "  부정행위: 25.4262\n",
      "  조건: 25.3586\n",
      "  손해배상: 23.2311\n",
      "  부정행위 조건: 21.1535\n",
      "  책임: 17.7814\n",
      "  배우자: 16.5995\n",
      "  정신: 15.2337\n",
      "  인정: 14.7464\n",
      "  자가: 14.6135\n",
      "  청구: 13.4194\n",
      "\n",
      "토픽 2:\n",
      "  재산: 11.5920\n",
      "  범위: 10.3312\n",
      "  분할: 9.8304\n",
      "  효력: 9.7343\n",
      "  관계: 9.1080\n",
      "  사실혼: 8.8724\n",
      "  기준: 7.7579\n",
      "  판단: 7.4158\n",
      "  이혼소송: 7.1094\n",
      "  법률: 6.5353\n",
      "\n",
      "토픽 3:\n",
      "  부정행위: 21.9430\n",
      "  손해배상: 19.1830\n",
      "  위자료: 17.6841\n",
      "  배우자: 17.6053\n",
      "  청구: 17.0722\n",
      "  기준: 16.3779\n",
      "  배우자 부정행위: 13.2264\n",
      "  정신: 12.8199\n",
      "  부정행위 기준: 12.6538\n",
      "  대한: 11.5298\n",
      "\n",
      "토픽 4:\n",
      "  생활: 16.3974\n",
      "  부부: 15.4108\n",
      "  자가: 11.6718\n",
      "  침해: 10.9257\n",
      "  책임: 9.7229\n",
      "  혼인: 9.4150\n",
      "  불법행위: 9.1919\n",
      "  부부 불법행위: 8.7234\n",
      "  하나요: 8.5515\n",
      "  일방: 6.7546\n"
     ]
    }
   ],
   "source": [
    "# 토픽별 대표 단어 추출\n",
    "print(\"=== 토픽별 주요 단어 ===\")\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "for topic_idx, topic in enumerate(final_lda.components_):\n",
    "    # 각 토픽에서 가중치가 높은 상위 10개 단어 추출\n",
    "    top_words_idx = topic.argsort()[-10:][::-1]\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "    top_weights = [topic[i] for i in top_words_idx]\n",
    "    \n",
    "    print(f\"\\n토픽 {topic_idx}:\")\n",
    "    for word, weight in zip(top_words, top_weights):\n",
    "        print(f\"  {word}: {weight:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5da37e8e-84e2-4ee7-90b4-c4fbbec89df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA 결과 형태: (741, 6)\n"
     ]
    }
   ],
   "source": [
    "# 최적의 토픽 수로 LDA 모델 생성 \n",
    "final_lda = LatentDirichletAllocation(\n",
    "    n_components=6,    # 최적 토픽 수 사용\n",
    "    random_state=42,\n",
    "    max_iter=100,\n",
    "    learning_method='batch',         # 또는 'online'\n",
    "    doc_topic_prior=0.1,        # 문서-토픽 분포 조정\n",
    "    topic_word_prior=0.01     # 토픽-단어 분포 조정\n",
    ")\n",
    "\n",
    "# LDA 모델 훈련 및 토픽 확률 계산\n",
    "lda_result = final_lda.fit_transform(tfidf_matrix)\n",
    "\n",
    "# 각 문서의 주요 토픽 결정 (확률이 가장 높은 토픽)\n",
    "topic_assignments = np.argmax(lda_result, axis=1)\n",
    "\n",
    "print(f\"LDA 결과 형태: {lda_result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "90d5d95b-1923-452a-a36d-b7c3a2a91244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 토픽별 주요 단어 ===\n",
      "\n",
      "토픽 0:\n",
      "  의무: 13.4350\n",
      "  지급: 9.6573\n",
      "  법적: 8.0409\n",
      "  양육비: 6.7887\n",
      "  약정: 5.5690\n",
      "  근거: 5.4483\n",
      "  대한: 5.4039\n",
      "  대한 기준: 5.1556\n",
      "  관련: 5.1415\n",
      "  부부 의무: 4.5447\n",
      "\n",
      "토픽 1:\n",
      "  조건: 26.7358\n",
      "  부정행위 조건: 21.1535\n",
      "  부정행위: 20.0830\n",
      "  손해배상: 16.6737\n",
      "  책임: 14.6157\n",
      "  배우자: 13.3136\n",
      "  자가: 12.6087\n",
      "  배우자 부정행위: 12.4383\n",
      "  일방: 10.8040\n",
      "  조건 책임: 10.5110\n",
      "\n",
      "토픽 2:\n",
      "  혼인: 12.4904\n",
      "  침해: 10.9257\n",
      "  관계: 9.6127\n",
      "  생활: 8.6037\n",
      "  효력: 7.3829\n",
      "  법률: 6.4168\n",
      "  생활 침해: 6.1245\n",
      "  부부: 5.9249\n",
      "  파탄: 5.4593\n",
      "  혼인 손해배상: 5.2935\n",
      "\n",
      "토픽 3:\n",
      "  손해배상: 25.4766\n",
      "  부정행위: 24.1695\n",
      "  청구: 21.2353\n",
      "  배우자: 19.3219\n",
      "  정신: 18.2584\n",
      "  청구 손해배상: 18.2321\n",
      "  위자료: 17.4927\n",
      "  기준: 17.1495\n",
      "  고통: 15.1484\n",
      "  손해배상 정신: 14.4894\n",
      "\n",
      "토픽 4:\n",
      "  부부: 13.7209\n",
      "  자가: 10.3482\n",
      "  법적: 8.5741\n",
      "  책임: 8.4037\n",
      "  발생: 8.3516\n",
      "  대해: 8.2373\n",
      "  생활: 7.8038\n",
      "  부부 불법행위: 7.4963\n",
      "  부정행위 일방: 7.2992\n",
      "  일방: 7.0558\n",
      "\n",
      "토픽 5:\n",
      "  재산: 23.4646\n",
      "  분할: 20.7766\n",
      "  이혼: 19.1640\n",
      "  사실혼: 8.4449\n",
      "  적용: 7.3631\n",
      "  조건: 7.2685\n",
      "  소송: 6.8551\n",
      "  청구: 6.5493\n",
      "  사해행위: 6.4323\n",
      "  고려: 6.1148\n"
     ]
    }
   ],
   "source": [
    "# 토픽별 대표 단어 추출\n",
    "print(\"=== 토픽별 주요 단어 ===\")\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "for topic_idx, topic in enumerate(final_lda.components_):\n",
    "    # 각 토픽에서 가중치가 높은 상위 10개 단어 추출\n",
    "    top_words_idx = topic.argsort()[-10:][::-1]\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "    top_weights = [topic[i] for i in top_words_idx]\n",
    "    \n",
    "    print(f\"\\n토픽 {topic_idx}:\")\n",
    "    for word, weight in zip(top_words, top_weights):\n",
    "        print(f\"  {word}: {weight:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28907455-4af9-40bf-a94c-dbf54cd33c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 토픽 수로 LDA 모델 생성 \n",
    "final_lda = LatentDirichletAllocation(\n",
    "    n_components=5,    # 최적 토픽 수 사용\n",
    "    random_state=42,\n",
    "    max_iter=100,\n",
    "    learning_method='batch',         # 또는 'online'\n",
    "    doc_topic_prior=0.1,        # 문서-토픽 분포 조정\n",
    "    topic_word_prior=0.01     # 토픽-단어 분포 조정\n",
    ")\n",
    "\n",
    "# LDA 모델 훈련 및 토픽 확률 계산\n",
    "lda_result = final_lda.fit_transform(tfidf_matrix)\n",
    "\n",
    "# 각 문서의 주요 토픽 결정 (확률이 가장 높은 토픽)\n",
    "topic_assignments = np.argmax(lda_result, axis=1)\n",
    "\n",
    "print(f\"LDA 결과 형태: {lda_result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5981d3-9ba5-4012-8337-a5cb6ff546e8",
   "metadata": {},
   "source": [
    "# 7단계: 최종 토픽 라벨 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3daed17d-2b5f-417c-94ef-c091cb35519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 토픽 라벨 분포:\n",
      "topic_label\n",
      "1    419\n",
      "0    322\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== 토픽 0 문서 예시 ===\n",
      "1. 부부 어떻다 부정행위 일방 책임 법적 지게 제3자가...\n",
      "2. 위자료 배우자 액수 정해지다 부정행위 어떻다 사람과...\n",
      "3. 배우자 어떻다 부정행위 책임 사람과 제3자는 법적...\n",
      "\n",
      "=== 토픽 1 문서 예시 ===\n",
      "1. 거래 차용 발생 청구권 관련 인정 조건 금전 혼인 반환...\n",
      "2. 규정 제조 사유 이혼 제840조 민법 부정 행위 제1호에서 제호 의미 재판...\n",
      "3. 법해 소송 어떻다 원상회복 부적 청구 채권자 취소 사해행위 다른...\n"
     ]
    }
   ],
   "source": [
    "# topic_label 컬럼에 최종 결과 저장\n",
    "divorce_df['topic_label'] = topic_assignments\n",
    "\n",
    "# 결과 확인\n",
    "print(\"최종 토픽 라벨 분포:\")\n",
    "print(divorce_df['topic_label'].value_counts())\n",
    "\n",
    "# 토픽별 문서 예시 확인\n",
    "for topic_idx in range(2):\n",
    "    print(f\"\\n=== 토픽 {topic_idx} 문서 예시 ===\")\n",
    "    topic_docs = divorce_df[divorce_df['topic_label'] == topic_idx]['input_processed']\n",
    "    for i, doc in enumerate(topic_docs.head(3)):\n",
    "        print(f\"{i+1}. {doc[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6cf2eb-1a66-49fc-bfcd-a0491221fdaa",
   "metadata": {},
   "source": [
    "# 8단계: K-Means 클러스터링 (비교 분석)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805515ec-7644-4f93-b153-bf1995a46291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means로도 클러스터링 수행 (비교용)\n",
    "kmeans_model = KMeans(\n",
    "    n_clusters=2,\n",
    "    random_state=42,\n",
    "    max_iter=300,\n",
    "    n_init=10  # 안정화\n",
    ")\n",
    "\n",
    "kmeans_labels = kmeans_model.fit_predict(tfidf_matrix)\n",
    "divorce_df['topic_label_kmeans'] = kmeans_labels\n",
    "\n",
    "# LDA와 K-Means 결과 비교\n",
    "comparison_df = pd.DataFrame({\n",
    "    'document_id': range(len(divorce_df)),\n",
    "    'lda_topic': topic_assignments,\n",
    "    'kmeans_cluster': kmeans_labels,\n",
    "    'input_text': divorce_df['input_processed'].apply(lambda x: x[:50] + '...' if len(x) > 50 else x)\n",
    "})\n",
    "\n",
    "print(\"LDA vs K-Means 결과 비교:\")\n",
    "print(comparison_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ebf43f-2d45-44c9-aa79-743e267b39ff",
   "metadata": {},
   "source": [
    "# 9단계: 결과 해석 및 토픽 명명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74e9f32f-513b-49f8-9db4-76ec01111374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 토픽별 상세 분석 ===\n",
      "\n",
      "토픽 0 (문서 322개):\n",
      "  부정행위: 15.2116\n",
      "  어떻다: 12.3022\n",
      "  위자료: 11.6667\n",
      "  청구: 11.5418\n",
      "  배우자: 11.4851\n",
      "  손해배상: 10.3333\n",
      "  부부: 9.3836\n",
      "  정신: 8.3524\n",
      "  인하다: 8.3454\n",
      "  조건: 8.1660\n",
      "\n",
      "토픽 1 (문서 419개):\n",
      "  부정행위: 21.0835\n",
      "  손해배상: 20.8283\n",
      "  인하다: 16.9923\n",
      "  청구: 16.3750\n",
      "  조건: 16.1127\n",
      "  책임: 15.6096\n",
      "  인정: 15.5422\n",
      "  어떻다: 15.4694\n",
      "  부부: 13.6787\n",
      "  인하다 손해배상: 12.4126\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 토픽별 상세 분석 ===\")\n",
    "for topic_idx, topic in enumerate(final_lda.components_):\n",
    "        top_words_idx = topic.argsort()[-15:][::-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        top_weights = [topic[i] for i in top_words_idx]\n",
    "\n",
    "        print(f\"\\n토픽 {topic_idx} (문서 {sum(topic_assignments == topic_idx)}개):\")\n",
    "        for word, weight in zip(top_words[:10], top_weights[:10]):\n",
    "            print(f\"  {word}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b4fce3d9-0fef-4b21-b492-0dd190a85639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  전체 데이터프레임 재조합\n",
    "final_df = pd.concat([divorce_df, non_divorce_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c8d46dd-5128-4cb4-a995-f6bf2a888264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 최종 토픽 분포:\n",
      "  토픽 -1 (미분류): 3706개\n",
      "  토픽 0: 322개\n",
      "  토픽 1: 419개\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n📈 최종 토픽 분포:\")\n",
    "topic_counts = final_df['topic_label'].value_counts().sort_index()\n",
    "for topic_id, count in topic_counts.items():\n",
    "    if topic_id == -1:\n",
    "        print(f\"  토픽 {topic_id} (미분류): {count}개\")\n",
    "    else:\n",
    "        print(f\"  토픽 {topic_id}: {count}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e9806-d5a2-4d7f-a615-c27644138ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽별 해석 (수동으로 의미를 부여)\n",
    "topic_interpretation = {}\n",
    "\n",
    "num_topics = len([t for t in topic_counts.index if t != -1])\n",
    "\n",
    "if num_topics == 2:\n",
    "        topic_interpretation = {\n",
    "            0: \"재산분할 관련\",\n",
    "            1: \"양육권/친권 관련\", \n",
    "            -1: \"비이혼 관련\"\n",
    "        }\n",
    "# elif num_topics == 4:\n",
    "#         topic_interpretation = {\n",
    "#             0: \"재산분할 관련\",\n",
    "#             1: \"양육권/친권 관련\",\n",
    "#             2: \"위자료 관련\",\n",
    "#             3: \"이혼절차 관련\",\n",
    "#             -1: \"비이혼 관련\"\n",
    "#         }\n",
    "# elif num_topics == 5:\n",
    "#         topic_interpretation = {\n",
    "#             0: \"재산분할 관련\",\n",
    "#             1: \"양육권/친권 관련\", \n",
    "#             2: \"위자료 관련\",\n",
    "#             3: \"이혼절차 관련\",\n",
    "#             4: \"기타 이혼 법률\",\n",
    "#             -1: \"비이혼 관련\"\n",
    "#         }\n",
    "else:\n",
    "        # 기본 해석\n",
    "        for i in range(num_topics):\n",
    "            topic_interpretation[i] = f\"이혼 토픽 {i}\"\n",
    "        topic_interpretation[-1] = \"비이혼 관련\"\n",
    "\n",
    "# 해석 추가\n",
    "final_df['topic_interpretation'] = final_df['topic_label'].map(topic_interpretation)\n",
    "\n",
    "print(f\"\\n🎯 토픽 해석:\")\n",
    "for topic_id, interpretation in topic_interpretation.items():\n",
    "        count = topic_counts.get(topic_id, 0)\n",
    "        print(f\"  토픽 {topic_id}: {interpretation} ({count}개)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85e20f-16e5-4861-a369-0d87ca8ce1d6",
   "metadata": {},
   "source": [
    "# 10단계: 결과 저장 및 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c69ee-5cf4-45a8-a6b7-f97f7b835eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "print(\"\\n=== 최종 결과 확인 ===\")\n",
    "print(final_df[['is_divorce', 'topic_label', 'topic_interpretation']].value_counts())\n",
    "\n",
    "# CSV 저장\n",
    "final_df.to_csv('divorce_topic_modeling_results.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n💾 결과가 'divorce_topic_modeling_results.csv'로 저장되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca0313-3fb6-4da5-ae4b-276f7fc247df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 CSV 파일로 저장\n",
    "final_results = combined_df[['input_processed', 'topic_label', 'topic_interpretation']].copy()\n",
    "final_results.to_csv('topic_modeling_results.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"토픽 모델링 완료! 결과가 저장되었습니다.\")\n",
    "print(f\"- 최적 토픽 수: {optimal_topics}\")\n",
    "print(f\"- 토픽 라벨 분포:\")\n",
    "for topic_id, count in combined_df['topic_label'].value_counts().sort_index().items():\n",
    "    interpretation = topic_interpretation.get(topic_id, \"해석 필요\")\n",
    "    print(f\"  토픽 {topic_id} ({interpretation}): {count}개 문서\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556bd0f-60da-424d-a90e-2fbabde98447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc5900-7d1d-4a4d-928a-b5f70e5abb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82935459-81da-4b92-abfc-48400300f93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f2b8e-0636-4070-beba-8caf02f25f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb85b3-032e-4853-bf63-92bf6a364135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6150ac-bcd4-47c0-9b39-1de61e4449eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data['clean_text']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927d537-e9ce-4008-9bdd-efda36bfeca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 로지스틱 회귀 학습\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f34e7-cfec-4fa7-86e2-7948820f895b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569b1df-15c7-45c7-b66f-517cf644b5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071737ee-fcde-4dde-bdd5-ceef2c244e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefa264-9806-476e-a9de-1daffe693baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
